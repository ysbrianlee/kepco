{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3f328c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from resnet_cifar10 import resnet_20, resnet_32, resnet_44, resnet_56, resnet_110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35377783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# 학습 및 테스트용 CIFAR-10 데이터셋 로드\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "# Class 개수와 이미지 크기 지정\n",
    "NUM_CLASSES = 10            # CIFAR-10 Dataset 은 10개의 class 를 가지고 있음\n",
    "IMG_HEIGHT = 32             # CIFAR-10 Dataset 의 이미지 크기 32x32x3\n",
    "IMG_WIDTH = 32\n",
    "\n",
    "# Epoch 횟수와 batch size, learning rate, dropout ratio 지정\n",
    "EPOCHS = 200                 # 학습 반복 횟수 지정\n",
    "BATCH_SIZE = 100            # 학습에 사용할 mini-batch 크기\n",
    "LEARNING_RATE = 0.001       # Optimizer 에 사용할 learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "852ee51a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding 형태로 label 데이터 변경\n",
    "y_train = tf.keras.utils.to_categorical(y_train, NUM_CLASSES)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, NUM_CLASSES)\n",
    "\n",
    "print(y_train.shape, y_test.shape)\n",
    "\n",
    "# ImageDataGenerator pipeline 을 이용한 Data augmentation\n",
    "# 학습용 데이터셋을 augmentation 하기 위한 ImageDataGenerator pipeline\n",
    "datagen = ImageDataGenerator(\n",
    "            featurewise_center=True,               # 각 이미지의 평균값에서 전체 데이터셋의 평균값을 빼서 분포의 평균을 0에 가깝게 만듦\n",
    "            featurewise_std_normalization=True,    # 평균이 0이고 분산이 1인 정규 분포를 따르도록 정규화\n",
    "            horizontal_flip=True,                  # random horizontal flip\n",
    "            width_shift_range=0.125,               # 좌/우로 이미지를 이동시켜 학습 데이터 늘림(0.125 : 전체 가로 크기의 12.5% 범위 내)\n",
    "            height_shift_range=0.125,              # 상/하로 이미지를 이동시켜 학습 데이터 늘림(0.125 : 전체 세로 크기의 12.5% 범위 내)\n",
    "            validation_split=0.2)                  # validation 에 사용할 데이터 비율(20%)\n",
    "\n",
    "# 테스트용 데이터셋을 augmentation 하기 위한 ImageDataGenerator pipeline\n",
    "test_datagen = ImageDataGenerator(\n",
    "            featurewise_center=True,\n",
    "            featurewise_std_normalization=True)\n",
    "\n",
    "# featurewise_center / featurewise_std_normalization 적용\n",
    "datagen.fit(x_train)\n",
    "test_datagen.fit(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1d54f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet-20 모델 생성\n",
    "model = resnet_20(NUM_CLASSES)\n",
    "\n",
    "# 학습에 사용할 SGD optimizer 및 loss function 생성\n",
    "optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "losses = tf.keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "# 모델 컴파일(optimizer, loss 지정)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=losses,\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be95d686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 1.8776 - acc: 0.3146\n",
      "Epoch 00001: val_acc improved from -inf to 0.36860, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 22s 54ms/step - loss: 1.8768 - acc: 0.3149 - val_loss: 1.7100 - val_acc: 0.3686\n",
      "Epoch 2/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.5749 - acc: 0.4215\n",
      "Epoch 00002: val_acc improved from 0.36860 to 0.42960, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 1.5749 - acc: 0.4215 - val_loss: 1.5561 - val_acc: 0.4296\n",
      "Epoch 3/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.4547 - acc: 0.4679\n",
      "Epoch 00003: val_acc improved from 0.42960 to 0.45460, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 1.4547 - acc: 0.4679 - val_loss: 1.5033 - val_acc: 0.4546\n",
      "Epoch 4/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.3576 - acc: 0.5055\n",
      "Epoch 00004: val_acc did not improve from 0.45460\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 1.3576 - acc: 0.5055 - val_loss: 1.5875 - val_acc: 0.4439\n",
      "Epoch 5/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 1.2907 - acc: 0.5304- ETA: 2s -\n",
      "Epoch 00005: val_acc improved from 0.45460 to 0.53520, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 1.2901 - acc: 0.5307 - val_loss: 1.2876 - val_acc: 0.5352\n",
      "Epoch 6/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.2232 - acc: 0.5579\n",
      "Epoch 00006: val_acc improved from 0.53520 to 0.55650, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 1.2232 - acc: 0.5579 - val_loss: 1.2284 - val_acc: 0.5565\n",
      "Epoch 7/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.1740 - acc: 0.5772\n",
      "Epoch 00007: val_acc did not improve from 0.55650\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 1.1740 - acc: 0.5772 - val_loss: 1.3192 - val_acc: 0.5326\n",
      "Epoch 8/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.1252 - acc: 0.5918\n",
      "Epoch 00008: val_acc improved from 0.55650 to 0.57570, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 54ms/step - loss: 1.1252 - acc: 0.5918 - val_loss: 1.1684 - val_acc: 0.5757\n",
      "Epoch 9/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 1.0840 - acc: 0.6083\n",
      "Epoch 00009: val_acc improved from 0.57570 to 0.58530, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 1.0843 - acc: 0.6080 - val_loss: 1.1517 - val_acc: 0.5853\n",
      "Epoch 10/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 1.0405 - acc: 0.6242\n",
      "Epoch 00010: val_acc did not improve from 0.58530\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 1.0405 - acc: 0.6242 - val_loss: 1.2051 - val_acc: 0.5726\n",
      "Epoch 11/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 1.0014 - acc: 0.6408\n",
      "Epoch 00011: val_acc improved from 0.58530 to 0.60060, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 1.0018 - acc: 0.6408 - val_loss: 1.1303 - val_acc: 0.6006\n",
      "Epoch 12/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.9656 - acc: 0.6544\n",
      "Epoch 00012: val_acc improved from 0.60060 to 0.64870, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.9649 - acc: 0.6547 - val_loss: 0.9897 - val_acc: 0.6487\n",
      "Epoch 13/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.9394 - acc: 0.6656\n",
      "Epoch 00013: val_acc did not improve from 0.64870\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.9394 - acc: 0.6656 - val_loss: 1.0142 - val_acc: 0.6378\n",
      "Epoch 14/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.9072 - acc: 0.6768\n",
      "Epoch 00014: val_acc did not improve from 0.64870\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.9070 - acc: 0.6769 - val_loss: 1.0561 - val_acc: 0.6240\n",
      "Epoch 15/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.8771 - acc: 0.6878\n",
      "Epoch 00015: val_acc did not improve from 0.64870\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.8771 - acc: 0.6878 - val_loss: 1.0189 - val_acc: 0.6396\n",
      "Epoch 16/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.8550 - acc: 0.6924\n",
      "Epoch 00016: val_acc improved from 0.64870 to 0.66880, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.8550 - acc: 0.6923 - val_loss: 0.9351 - val_acc: 0.6688\n",
      "Epoch 17/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.8259 - acc: 0.7056\n",
      "Epoch 00017: val_acc improved from 0.66880 to 0.67470, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.8259 - acc: 0.7056 - val_loss: 0.9139 - val_acc: 0.6747\n",
      "Epoch 18/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.8052 - acc: 0.7163\n",
      "Epoch 00018: val_acc improved from 0.67470 to 0.69510, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.8051 - acc: 0.7163 - val_loss: 0.8475 - val_acc: 0.6951\n",
      "Epoch 19/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.7897 - acc: 0.7210\n",
      "Epoch 00019: val_acc did not improve from 0.69510\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.7898 - acc: 0.7209 - val_loss: 0.8712 - val_acc: 0.6876\n",
      "Epoch 20/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.7714 - acc: 0.7280\n",
      "Epoch 00020: val_acc improved from 0.69510 to 0.69620, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.7712 - acc: 0.7280 - val_loss: 0.8531 - val_acc: 0.6962\n",
      "Epoch 21/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.7470 - acc: 0.7375\n",
      "Epoch 00021: val_acc improved from 0.69620 to 0.69880, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.7470 - acc: 0.7375 - val_loss: 0.8637 - val_acc: 0.6988\n",
      "Epoch 22/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.7274 - acc: 0.7414\n",
      "Epoch 00022: val_acc did not improve from 0.69880\n",
      "400/400 [==============================] - 21s 51ms/step - loss: 0.7280 - acc: 0.7410 - val_loss: 0.9146 - val_acc: 0.6857\n",
      "Epoch 23/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.7089 - acc: 0.7484\n",
      "Epoch 00023: val_acc improved from 0.69880 to 0.71770, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 21s 52ms/step - loss: 0.7086 - acc: 0.7485 - val_loss: 0.8039 - val_acc: 0.7177\n",
      "Epoch 24/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6957 - acc: 0.7547\n",
      "Epoch 00024: val_acc did not improve from 0.71770\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6957 - acc: 0.7548 - val_loss: 0.9226 - val_acc: 0.6739\n",
      "Epoch 25/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6795 - acc: 0.7636\n",
      "Epoch 00025: val_acc improved from 0.71770 to 0.72030, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6798 - acc: 0.7635 - val_loss: 0.8121 - val_acc: 0.7203\n",
      "Epoch 26/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6665 - acc: 0.7663\n",
      "Epoch 00026: val_acc did not improve from 0.72030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6668 - acc: 0.7661 - val_loss: 0.8566 - val_acc: 0.7088\n",
      "Epoch 27/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6521 - acc: 0.7709\n",
      "Epoch 00027: val_acc improved from 0.72030 to 0.72520, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6521 - acc: 0.7708 - val_loss: 0.8050 - val_acc: 0.7252\n",
      "Epoch 28/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6403 - acc: 0.7767\n",
      "Epoch 00028: val_acc improved from 0.72520 to 0.74170, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6404 - acc: 0.7767 - val_loss: 0.7412 - val_acc: 0.7417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.6306 - acc: 0.7781\n",
      "Epoch 00029: val_acc improved from 0.74170 to 0.75240, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.6306 - acc: 0.7781 - val_loss: 0.7278 - val_acc: 0.7524\n",
      "Epoch 30/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6154 - acc: 0.7833\n",
      "Epoch 00030: val_acc did not improve from 0.75240\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6150 - acc: 0.7835 - val_loss: 0.7654 - val_acc: 0.7342\n",
      "Epoch 31/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.6026 - acc: 0.7905\n",
      "Epoch 00031: val_acc did not improve from 0.75240\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.6027 - acc: 0.7906 - val_loss: 0.7714 - val_acc: 0.7338\n",
      "Epoch 32/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.5937 - acc: 0.7908\n",
      "Epoch 00032: val_acc improved from 0.75240 to 0.76440, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.5936 - acc: 0.7910 - val_loss: 0.6810 - val_acc: 0.7644\n",
      "Epoch 33/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.5788 - acc: 0.7970\n",
      "Epoch 00033: val_acc did not improve from 0.76440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5787 - acc: 0.7970 - val_loss: 0.7750 - val_acc: 0.7363\n",
      "Epoch 34/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5698 - acc: 0.8003\n",
      "Epoch 00034: val_acc did not improve from 0.76440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5698 - acc: 0.8003 - val_loss: 0.7643 - val_acc: 0.7291\n",
      "Epoch 35/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5624 - acc: 0.8020\n",
      "Epoch 00035: val_acc improved from 0.76440 to 0.76730, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.5624 - acc: 0.8020 - val_loss: 0.6815 - val_acc: 0.7673\n",
      "Epoch 36/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5527 - acc: 0.8033\n",
      "Epoch 00036: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5527 - acc: 0.8033 - val_loss: 0.6872 - val_acc: 0.7636\n",
      "Epoch 37/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5423 - acc: 0.8104\n",
      "Epoch 00037: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5423 - acc: 0.8104 - val_loss: 0.6816 - val_acc: 0.7662\n",
      "Epoch 38/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.5329 - acc: 0.8133\n",
      "Epoch 00038: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5329 - acc: 0.8133 - val_loss: 0.7023 - val_acc: 0.7553\n",
      "Epoch 39/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.5217 - acc: 0.8173\n",
      "Epoch 00039: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5217 - acc: 0.8173 - val_loss: 0.6990 - val_acc: 0.7611\n",
      "Epoch 40/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.5149 - acc: 0.8193\n",
      "Epoch 00040: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5149 - acc: 0.8193 - val_loss: 0.8437 - val_acc: 0.7277\n",
      "Epoch 41/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.5083 - acc: 0.8206\n",
      "Epoch 00041: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.5081 - acc: 0.8206 - val_loss: 0.7437 - val_acc: 0.7535\n",
      "Epoch 42/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4997 - acc: 0.8248\n",
      "Epoch 00042: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4997 - acc: 0.8248 - val_loss: 0.6721 - val_acc: 0.7667\n",
      "Epoch 43/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4921 - acc: 0.8273\n",
      "Epoch 00043: val_acc did not improve from 0.76730\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4922 - acc: 0.8273 - val_loss: 0.6930 - val_acc: 0.7647\n",
      "Epoch 44/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4860 - acc: 0.8291\n",
      "Epoch 00044: val_acc improved from 0.76730 to 0.77680, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.4859 - acc: 0.8291 - val_loss: 0.6474 - val_acc: 0.7768\n",
      "Epoch 45/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4750 - acc: 0.8342\n",
      "Epoch 00045: val_acc improved from 0.77680 to 0.77830, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.4749 - acc: 0.8343 - val_loss: 0.6546 - val_acc: 0.7783\n",
      "Epoch 46/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4698 - acc: 0.8354\n",
      "Epoch 00046: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4698 - acc: 0.8354 - val_loss: 0.7398 - val_acc: 0.7474\n",
      "Epoch 47/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4596 - acc: 0.8389\n",
      "Epoch 00047: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4596 - acc: 0.8389 - val_loss: 0.6793 - val_acc: 0.7749\n",
      "Epoch 48/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4544 - acc: 0.8416\n",
      "Epoch 00048: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4544 - acc: 0.8416 - val_loss: 0.7095 - val_acc: 0.7643\n",
      "Epoch 49/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4491 - acc: 0.8428\n",
      "Epoch 00049: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4491 - acc: 0.8428 - val_loss: 0.7151 - val_acc: 0.7605\n",
      "Epoch 50/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4400 - acc: 0.8441\n",
      "Epoch 00050: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4402 - acc: 0.8439 - val_loss: 0.6771 - val_acc: 0.7722\n",
      "Epoch 51/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4371 - acc: 0.8469\n",
      "Epoch 00051: val_acc did not improve from 0.77830\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4370 - acc: 0.8469 - val_loss: 0.6886 - val_acc: 0.7734\n",
      "Epoch 52/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4259 - acc: 0.8521\n",
      "Epoch 00052: val_acc improved from 0.77830 to 0.79860, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.4259 - acc: 0.8521 - val_loss: 0.5945 - val_acc: 0.7986\n",
      "Epoch 53/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4197 - acc: 0.8523\n",
      "Epoch 00053: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 21s 53ms/step - loss: 0.4195 - acc: 0.8524 - val_loss: 0.6801 - val_acc: 0.7781\n",
      "Epoch 54/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4175 - acc: 0.8529\n",
      "Epoch 00054: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.4178 - acc: 0.8528 - val_loss: 0.7289 - val_acc: 0.7606\n",
      "Epoch 55/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.4109 - acc: 0.8559\n",
      "Epoch 00055: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4111 - acc: 0.8559 - val_loss: 0.6103 - val_acc: 0.7901\n",
      "Epoch 56/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.4064 - acc: 0.8560\n",
      "Epoch 00056: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.4064 - acc: 0.8560 - val_loss: 0.6820 - val_acc: 0.7777\n",
      "Epoch 57/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3955 - acc: 0.8607\n",
      "Epoch 00057: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3956 - acc: 0.8607 - val_loss: 0.6816 - val_acc: 0.7736\n",
      "Epoch 58/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3962 - acc: 0.8614\n",
      "Epoch 00058: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3961 - acc: 0.8614 - val_loss: 0.6176 - val_acc: 0.7922\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3891 - acc: 0.8639\n",
      "Epoch 00059: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3888 - acc: 0.8640 - val_loss: 0.6646 - val_acc: 0.7812\n",
      "Epoch 60/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3816 - acc: 0.8636\n",
      "Epoch 00060: val_acc did not improve from 0.79860\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3813 - acc: 0.8637 - val_loss: 0.6246 - val_acc: 0.7932\n",
      "Epoch 61/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3741 - acc: 0.8682\n",
      "Epoch 00061: val_acc improved from 0.79860 to 0.80120, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.3741 - acc: 0.8682 - val_loss: 0.6073 - val_acc: 0.8012\n",
      "Epoch 62/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3754 - acc: 0.8675\n",
      "Epoch 00062: val_acc did not improve from 0.80120\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3753 - acc: 0.8675 - val_loss: 0.6010 - val_acc: 0.7979\n",
      "Epoch 63/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3711 - acc: 0.8694\n",
      "Epoch 00063: val_acc did not improve from 0.80120\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3711 - acc: 0.8694 - val_loss: 0.6321 - val_acc: 0.7886\n",
      "Epoch 64/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3612 - acc: 0.8725\n",
      "Epoch 00064: val_acc did not improve from 0.80120\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3612 - acc: 0.8725 - val_loss: 0.6253 - val_acc: 0.7908\n",
      "Epoch 65/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3571 - acc: 0.8748\n",
      "Epoch 00065: val_acc did not improve from 0.80120\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3571 - acc: 0.8748 - val_loss: 0.6664 - val_acc: 0.7808\n",
      "Epoch 66/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3495 - acc: 0.8775\n",
      "Epoch 00066: val_acc improved from 0.80120 to 0.81030, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.3496 - acc: 0.8775 - val_loss: 0.5802 - val_acc: 0.8103\n",
      "Epoch 67/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3467 - acc: 0.8786\n",
      "Epoch 00067: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3468 - acc: 0.8786 - val_loss: 0.6985 - val_acc: 0.7803\n",
      "Epoch 68/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3445 - acc: 0.8794\n",
      "Epoch 00068: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3443 - acc: 0.8794 - val_loss: 0.6462 - val_acc: 0.7876\n",
      "Epoch 69/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3398 - acc: 0.8795\n",
      "Epoch 00069: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3398 - acc: 0.8795 - val_loss: 0.8023 - val_acc: 0.7448\n",
      "Epoch 70/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3351 - acc: 0.8815\n",
      "Epoch 00070: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3353 - acc: 0.8814 - val_loss: 0.6552 - val_acc: 0.7932\n",
      "Epoch 71/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3338 - acc: 0.8840\n",
      "Epoch 00071: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3338 - acc: 0.8840 - val_loss: 0.6136 - val_acc: 0.8082\n",
      "Epoch 72/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3250 - acc: 0.8867\n",
      "Epoch 00072: val_acc did not improve from 0.81030\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3247 - acc: 0.8869 - val_loss: 0.6098 - val_acc: 0.7992\n",
      "Epoch 73/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3217 - acc: 0.8867\n",
      "Epoch 00073: val_acc improved from 0.81030 to 0.81440, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.3220 - acc: 0.8866 - val_loss: 0.5697 - val_acc: 0.8144\n",
      "Epoch 74/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3123 - acc: 0.8889\n",
      "Epoch 00074: val_acc did not improve from 0.81440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3123 - acc: 0.8889 - val_loss: 0.5948 - val_acc: 0.8020\n",
      "Epoch 75/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3137 - acc: 0.8903\n",
      "Epoch 00075: val_acc did not improve from 0.81440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3138 - acc: 0.8902 - val_loss: 0.7404 - val_acc: 0.7707\n",
      "Epoch 76/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3057 - acc: 0.8915\n",
      "Epoch 00076: val_acc did not improve from 0.81440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3058 - acc: 0.8914 - val_loss: 0.5898 - val_acc: 0.8088\n",
      "Epoch 77/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.3038 - acc: 0.8915\n",
      "Epoch 00077: val_acc did not improve from 0.81440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3038 - acc: 0.8915 - val_loss: 0.6514 - val_acc: 0.7941\n",
      "Epoch 78/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.3044 - acc: 0.8919\n",
      "Epoch 00078: val_acc did not improve from 0.81440\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.3043 - acc: 0.8919 - val_loss: 0.6261 - val_acc: 0.8022\n",
      "Epoch 79/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2959 - acc: 0.8952\n",
      "Epoch 00079: val_acc improved from 0.81440 to 0.81850, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2959 - acc: 0.8952 - val_loss: 0.5537 - val_acc: 0.8185\n",
      "Epoch 80/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2971 - acc: 0.8941\n",
      "Epoch 00080: val_acc did not improve from 0.81850\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2972 - acc: 0.8940 - val_loss: 0.6089 - val_acc: 0.8059\n",
      "Epoch 81/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2611 - acc: 0.9074\n",
      "Epoch 00081: val_acc improved from 0.81850 to 0.83190, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2612 - acc: 0.9074 - val_loss: 0.5010 - val_acc: 0.8319\n",
      "Epoch 82/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2477 - acc: 0.9123\n",
      "Epoch 00082: val_acc improved from 0.83190 to 0.84040, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2477 - acc: 0.9123 - val_loss: 0.4919 - val_acc: 0.8404\n",
      "Epoch 83/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2469 - acc: 0.9135\n",
      "Epoch 00083: val_acc did not improve from 0.84040\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2469 - acc: 0.9135 - val_loss: 0.4953 - val_acc: 0.8387\n",
      "Epoch 84/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2416 - acc: 0.9155\n",
      "Epoch 00084: val_acc improved from 0.84040 to 0.84060, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2416 - acc: 0.9154 - val_loss: 0.4875 - val_acc: 0.8406\n",
      "Epoch 85/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2383 - acc: 0.9168\n",
      "Epoch 00085: val_acc improved from 0.84060 to 0.84110, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 23s 58ms/step - loss: 0.2384 - acc: 0.9168 - val_loss: 0.4872 - val_acc: 0.8411\n",
      "Epoch 86/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2325 - acc: 0.9187\n",
      "Epoch 00086: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2325 - acc: 0.9187 - val_loss: 0.4815 - val_acc: 0.8394\n",
      "Epoch 87/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2323 - acc: 0.9201\n",
      "Epoch 00087: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2322 - acc: 0.9201 - val_loss: 0.4908 - val_acc: 0.8366\n",
      "Epoch 88/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2317 - acc: 0.9203\n",
      "Epoch 00088: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2318 - acc: 0.9204 - val_loss: 0.4826 - val_acc: 0.8368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 89/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2291 - acc: 0.9212\n",
      "Epoch 00089: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2290 - acc: 0.9213 - val_loss: 0.5018 - val_acc: 0.8332\n",
      "Epoch 90/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2320 - acc: 0.9181\n",
      "Epoch 00090: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2318 - acc: 0.9182 - val_loss: 0.4959 - val_acc: 0.8375\n",
      "Epoch 91/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2262 - acc: 0.9211\n",
      "Epoch 00091: val_acc did not improve from 0.84110\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2262 - acc: 0.9212 - val_loss: 0.5053 - val_acc: 0.8367\n",
      "Epoch 92/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2283 - acc: 0.9211\n",
      "Epoch 00092: val_acc improved from 0.84110 to 0.84240, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2286 - acc: 0.9210 - val_loss: 0.4854 - val_acc: 0.8424\n",
      "Epoch 93/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2297 - acc: 0.9204\n",
      "Epoch 00093: val_acc did not improve from 0.84240\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2297 - acc: 0.9204 - val_loss: 0.4897 - val_acc: 0.8361\n",
      "Epoch 94/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2270 - acc: 0.9219\n",
      "Epoch 00094: val_acc did not improve from 0.84240\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2270 - acc: 0.9219 - val_loss: 0.4832 - val_acc: 0.8384\n",
      "Epoch 95/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2282 - acc: 0.9203\n",
      "Epoch 00095: val_acc improved from 0.84240 to 0.84300, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2282 - acc: 0.9202 - val_loss: 0.4928 - val_acc: 0.8430\n",
      "Epoch 96/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2248 - acc: 0.9219\n",
      "Epoch 00096: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2248 - acc: 0.9219 - val_loss: 0.5040 - val_acc: 0.8396\n",
      "Epoch 97/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2234 - acc: 0.9228\n",
      "Epoch 00097: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2233 - acc: 0.9228 - val_loss: 0.5003 - val_acc: 0.8377\n",
      "Epoch 98/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2194 - acc: 0.9240\n",
      "Epoch 00098: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2194 - acc: 0.9240 - val_loss: 0.4921 - val_acc: 0.8404\n",
      "Epoch 99/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2231 - acc: 0.9229\n",
      "Epoch 00099: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2230 - acc: 0.9230 - val_loss: 0.4996 - val_acc: 0.8368\n",
      "Epoch 100/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2236 - acc: 0.9222\n",
      "Epoch 00100: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2236 - acc: 0.9222 - val_loss: 0.4872 - val_acc: 0.8428\n",
      "Epoch 101/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2222 - acc: 0.9219\n",
      "Epoch 00101: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2222 - acc: 0.9219 - val_loss: 0.4900 - val_acc: 0.8394\n",
      "Epoch 102/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2198 - acc: 0.9238\n",
      "Epoch 00102: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2198 - acc: 0.9238 - val_loss: 0.4955 - val_acc: 0.8407\n",
      "Epoch 103/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2170 - acc: 0.9243\n",
      "Epoch 00103: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2173 - acc: 0.9242 - val_loss: 0.4923 - val_acc: 0.8403\n",
      "Epoch 104/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2186 - acc: 0.9230\n",
      "Epoch 00104: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2186 - acc: 0.9230 - val_loss: 0.4898 - val_acc: 0.8401\n",
      "Epoch 105/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2185 - acc: 0.9241\n",
      "Epoch 00105: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2185 - acc: 0.9241 - val_loss: 0.4894 - val_acc: 0.8386\n",
      "Epoch 106/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2204 - acc: 0.9238\n",
      "Epoch 00106: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2204 - acc: 0.9238 - val_loss: 0.4949 - val_acc: 0.8385\n",
      "Epoch 107/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2143 - acc: 0.9255\n",
      "Epoch 00107: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2143 - acc: 0.9255 - val_loss: 0.4903 - val_acc: 0.8399\n",
      "Epoch 108/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2167 - acc: 0.9244\n",
      "Epoch 00108: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2165 - acc: 0.9244 - val_loss: 0.4978 - val_acc: 0.8377\n",
      "Epoch 109/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2163 - acc: 0.9234\n",
      "Epoch 00109: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2164 - acc: 0.9233 - val_loss: 0.4933 - val_acc: 0.8415\n",
      "Epoch 110/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2119 - acc: 0.9265\n",
      "Epoch 00110: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2120 - acc: 0.9265 - val_loss: 0.5073 - val_acc: 0.8369\n",
      "Epoch 111/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2120 - acc: 0.9259\n",
      "Epoch 00111: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2120 - acc: 0.9259 - val_loss: 0.4898 - val_acc: 0.8384\n",
      "Epoch 112/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2176 - acc: 0.9253\n",
      "Epoch 00112: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2176 - acc: 0.9253 - val_loss: 0.4956 - val_acc: 0.8430\n",
      "Epoch 113/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2125 - acc: 0.9259\n",
      "Epoch 00113: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2124 - acc: 0.9260 - val_loss: 0.4971 - val_acc: 0.8391\n",
      "Epoch 114/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2118 - acc: 0.9244\n",
      "Epoch 00114: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2120 - acc: 0.9244 - val_loss: 0.5045 - val_acc: 0.8341\n",
      "Epoch 115/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2132 - acc: 0.9245\n",
      "Epoch 00115: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2132 - acc: 0.9245 - val_loss: 0.5125 - val_acc: 0.8359\n",
      "Epoch 116/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2114 - acc: 0.9267\n",
      "Epoch 00116: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2115 - acc: 0.9266 - val_loss: 0.5125 - val_acc: 0.8358\n",
      "Epoch 117/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2088 - acc: 0.9272\n",
      "Epoch 00117: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2091 - acc: 0.9270 - val_loss: 0.5095 - val_acc: 0.8422\n",
      "Epoch 118/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2127 - acc: 0.9262\n",
      "Epoch 00118: val_acc did not improve from 0.84300\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2126 - acc: 0.9262 - val_loss: 0.5069 - val_acc: 0.8335\n",
      "Epoch 119/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2083 - acc: 0.9272\n",
      "Epoch 00119: val_acc improved from 0.84300 to 0.84310, saving model to trained_model\\checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 21s 52ms/step - loss: 0.2084 - acc: 0.9272 - val_loss: 0.4923 - val_acc: 0.8431\n",
      "Epoch 120/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2093 - acc: 0.9280\n",
      "Epoch 00120: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2094 - acc: 0.9280 - val_loss: 0.4963 - val_acc: 0.8416\n",
      "Epoch 121/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2040 - acc: 0.9287\n",
      "Epoch 00121: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2040 - acc: 0.9287 - val_loss: 0.4932 - val_acc: 0.8371\n",
      "Epoch 122/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2048 - acc: 0.9287\n",
      "Epoch 00122: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2047 - acc: 0.9287 - val_loss: 0.4919 - val_acc: 0.8353\n",
      "Epoch 123/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2066 - acc: 0.9280\n",
      "Epoch 00123: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2066 - acc: 0.9280 - val_loss: 0.5018 - val_acc: 0.8400\n",
      "Epoch 124/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2031 - acc: 0.9282\n",
      "Epoch 00124: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2035 - acc: 0.9280 - val_loss: 0.5035 - val_acc: 0.8375\n",
      "Epoch 125/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2050 - acc: 0.9284\n",
      "Epoch 00125: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2050 - acc: 0.9284 - val_loss: 0.4970 - val_acc: 0.8418\n",
      "Epoch 126/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2041 - acc: 0.9295\n",
      "Epoch 00126: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2041 - acc: 0.9295 - val_loss: 0.4923 - val_acc: 0.8422\n",
      "Epoch 127/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2041 - acc: 0.9297\n",
      "Epoch 00127: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2041 - acc: 0.9297 - val_loss: 0.4966 - val_acc: 0.8401\n",
      "Epoch 128/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2035 - acc: 0.9296\n",
      "Epoch 00128: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2035 - acc: 0.9296 - val_loss: 0.4965 - val_acc: 0.8382\n",
      "Epoch 129/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9299\n",
      "Epoch 00129: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2013 - acc: 0.9299 - val_loss: 0.4934 - val_acc: 0.8419\n",
      "Epoch 130/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1991 - acc: 0.9308\n",
      "Epoch 00130: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1991 - acc: 0.9308 - val_loss: 0.4950 - val_acc: 0.8391\n",
      "Epoch 131/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2052 - acc: 0.9286\n",
      "Epoch 00131: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2051 - acc: 0.9287 - val_loss: 0.5080 - val_acc: 0.8400\n",
      "Epoch 132/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2036 - acc: 0.9294\n",
      "Epoch 00132: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2038 - acc: 0.9294 - val_loss: 0.4987 - val_acc: 0.8423\n",
      "Epoch 133/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2071 - acc: 0.9282\n",
      "Epoch 00133: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2069 - acc: 0.9282 - val_loss: 0.4983 - val_acc: 0.8411\n",
      "Epoch 134/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2060 - acc: 0.9290\n",
      "Epoch 00134: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2060 - acc: 0.9290 - val_loss: 0.4972 - val_acc: 0.8380\n",
      "Epoch 135/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1977 - acc: 0.9307\n",
      "Epoch 00135: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1976 - acc: 0.9307 - val_loss: 0.4927 - val_acc: 0.8424\n",
      "Epoch 136/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2008 - acc: 0.9294\n",
      "Epoch 00136: val_acc did not improve from 0.84310\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2008 - acc: 0.9294 - val_loss: 0.4898 - val_acc: 0.8412\n",
      "Epoch 137/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2039 - acc: 0.9299\n",
      "Epoch 00137: val_acc improved from 0.84310 to 0.84530, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2038 - acc: 0.9300 - val_loss: 0.4833 - val_acc: 0.8453\n",
      "Epoch 138/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2040 - acc: 0.9293\n",
      "Epoch 00138: val_acc did not improve from 0.84530\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2038 - acc: 0.9294 - val_loss: 0.4965 - val_acc: 0.8429\n",
      "Epoch 139/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2023 - acc: 0.9312\n",
      "Epoch 00139: val_acc did not improve from 0.84530\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2023 - acc: 0.9312 - val_loss: 0.5041 - val_acc: 0.8414\n",
      "Epoch 140/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9295\n",
      "Epoch 00140: val_acc did not improve from 0.84530\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2033 - acc: 0.9295 - val_loss: 0.5049 - val_acc: 0.8414\n",
      "Epoch 141/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2037 - acc: 0.9290\n",
      "Epoch 00141: val_acc improved from 0.84530 to 0.84560, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.2039 - acc: 0.9289 - val_loss: 0.4811 - val_acc: 0.8456\n",
      "Epoch 142/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2061 - acc: 0.9281\n",
      "Epoch 00142: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2061 - acc: 0.9281 - val_loss: 0.4918 - val_acc: 0.8402\n",
      "Epoch 143/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2012 - acc: 0.9304\n",
      "Epoch 00143: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2012 - acc: 0.9304 - val_loss: 0.4893 - val_acc: 0.8417\n",
      "Epoch 144/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2020 - acc: 0.9299\n",
      "Epoch 00144: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2020 - acc: 0.9299 - val_loss: 0.4997 - val_acc: 0.8400\n",
      "Epoch 145/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2024 - acc: 0.9297\n",
      "Epoch 00145: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2025 - acc: 0.9297 - val_loss: 0.4914 - val_acc: 0.8445\n",
      "Epoch 146/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1990 - acc: 0.9309\n",
      "Epoch 00146: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1990 - acc: 0.9308 - val_loss: 0.4964 - val_acc: 0.8417\n",
      "Epoch 147/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1997 - acc: 0.9307\n",
      "Epoch 00147: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1997 - acc: 0.9308 - val_loss: 0.4901 - val_acc: 0.8425\n",
      "Epoch 148/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2034 - acc: 0.9297\n",
      "Epoch 00148: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2034 - acc: 0.9297 - val_loss: 0.4959 - val_acc: 0.8440\n",
      "Epoch 149/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9306\n",
      "Epoch 00149: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1994 - acc: 0.9306 - val_loss: 0.4960 - val_acc: 0.8419\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2003 - acc: 0.9297\n",
      "Epoch 00150: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2001 - acc: 0.9298 - val_loss: 0.5006 - val_acc: 0.8375\n",
      "Epoch 151/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2016 - acc: 0.9296\n",
      "Epoch 00151: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2015 - acc: 0.9297 - val_loss: 0.4959 - val_acc: 0.8372\n",
      "Epoch 152/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9316\n",
      "Epoch 00152: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1980 - acc: 0.9316 - val_loss: 0.4973 - val_acc: 0.8397\n",
      "Epoch 153/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9288\n",
      "Epoch 00153: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2020 - acc: 0.9288 - val_loss: 0.4899 - val_acc: 0.8422\n",
      "Epoch 154/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1988 - acc: 0.9304\n",
      "Epoch 00154: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1988 - acc: 0.9304 - val_loss: 0.4954 - val_acc: 0.8420\n",
      "Epoch 155/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2032 - acc: 0.9289\n",
      "Epoch 00155: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2031 - acc: 0.9289 - val_loss: 0.4983 - val_acc: 0.8401\n",
      "Epoch 156/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1988 - acc: 0.9306\n",
      "Epoch 00156: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1989 - acc: 0.9305 - val_loss: 0.4893 - val_acc: 0.8380\n",
      "Epoch 157/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9304\n",
      "Epoch 00157: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2011 - acc: 0.9304 - val_loss: 0.4921 - val_acc: 0.8448\n",
      "Epoch 158/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2036 - acc: 0.9288\n",
      "Epoch 00158: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2036 - acc: 0.9288 - val_loss: 0.4916 - val_acc: 0.8452\n",
      "Epoch 159/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9295\n",
      "Epoch 00159: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2019 - acc: 0.9297 - val_loss: 0.4994 - val_acc: 0.8437\n",
      "Epoch 160/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2050 - acc: 0.9276\n",
      "Epoch 00160: val_acc did not improve from 0.84560\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2049 - acc: 0.9276 - val_loss: 0.4993 - val_acc: 0.8433\n",
      "Epoch 161/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9295\n",
      "Epoch 00161: val_acc improved from 0.84560 to 0.84780, saving model to trained_model\\checkpoint\n",
      "400/400 [==============================] - 20s 51ms/step - loss: 0.1995 - acc: 0.9295 - val_loss: 0.4791 - val_acc: 0.8478\n",
      "Epoch 162/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1994 - acc: 0.9301\n",
      "Epoch 00162: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1994 - acc: 0.9301 - val_loss: 0.5008 - val_acc: 0.8429\n",
      "Epoch 163/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1977 - acc: 0.9307\n",
      "Epoch 00163: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1977 - acc: 0.9307 - val_loss: 0.4971 - val_acc: 0.8376\n",
      "Epoch 164/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2001 - acc: 0.9314\n",
      "Epoch 00164: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2001 - acc: 0.9314 - val_loss: 0.4849 - val_acc: 0.8448\n",
      "Epoch 165/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2002 - acc: 0.9302\n",
      "Epoch 00165: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2003 - acc: 0.9302 - val_loss: 0.5040 - val_acc: 0.8367\n",
      "Epoch 166/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9298\n",
      "Epoch 00166: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1997 - acc: 0.9298 - val_loss: 0.5004 - val_acc: 0.8430\n",
      "Epoch 167/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2021 - acc: 0.9304\n",
      "Epoch 00167: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 22s 55ms/step - loss: 0.2019 - acc: 0.9305 - val_loss: 0.4914 - val_acc: 0.8420\n",
      "Epoch 168/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2022 - acc: 0.9288\n",
      "Epoch 00168: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2023 - acc: 0.9288 - val_loss: 0.4987 - val_acc: 0.8416\n",
      "Epoch 169/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2005 - acc: 0.9303\n",
      "Epoch 00169: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2004 - acc: 0.9304 - val_loss: 0.4935 - val_acc: 0.8406\n",
      "Epoch 170/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9301\n",
      "Epoch 00170: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1992 - acc: 0.9301 - val_loss: 0.5043 - val_acc: 0.8403\n",
      "Epoch 171/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2026 - acc: 0.9297\n",
      "Epoch 00171: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2028 - acc: 0.9297 - val_loss: 0.4927 - val_acc: 0.8426\n",
      "Epoch 172/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2000 - acc: 0.9306\n",
      "Epoch 00172: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2000 - acc: 0.9306 - val_loss: 0.4968 - val_acc: 0.8390\n",
      "Epoch 173/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1969 - acc: 0.9312\n",
      "Epoch 00173: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1969 - acc: 0.9312 - val_loss: 0.5066 - val_acc: 0.8426\n",
      "Epoch 174/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9314\n",
      "Epoch 00174: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1980 - acc: 0.9314 - val_loss: 0.4992 - val_acc: 0.8408\n",
      "Epoch 175/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1975 - acc: 0.9322\n",
      "Epoch 00175: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 23s 59ms/step - loss: 0.1975 - acc: 0.9322 - val_loss: 0.5047 - val_acc: 0.8403\n",
      "Epoch 176/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2013 - acc: 0.9314\n",
      "Epoch 00176: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2011 - acc: 0.9315 - val_loss: 0.5086 - val_acc: 0.8379\n",
      "Epoch 177/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.2013 - acc: 0.9307\n",
      "Epoch 00177: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2013 - acc: 0.9307 - val_loss: 0.4886 - val_acc: 0.8457\n",
      "Epoch 178/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9314\n",
      "Epoch 00178: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1977 - acc: 0.9313 - val_loss: 0.4936 - val_acc: 0.8451\n",
      "Epoch 179/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9297\n",
      "Epoch 00179: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2010 - acc: 0.9298 - val_loss: 0.5086 - val_acc: 0.8339\n",
      "Epoch 180/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9297\n",
      "Epoch 00180: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1996 - acc: 0.9297 - val_loss: 0.4926 - val_acc: 0.8436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 181/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9312\n",
      "Epoch 00181: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1995 - acc: 0.9312 - val_loss: 0.4900 - val_acc: 0.8428\n",
      "Epoch 182/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1971 - acc: 0.9315\n",
      "Epoch 00182: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1973 - acc: 0.9313 - val_loss: 0.5058 - val_acc: 0.8402\n",
      "Epoch 183/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2027 - acc: 0.9290\n",
      "Epoch 00183: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2027 - acc: 0.9290 - val_loss: 0.4916 - val_acc: 0.8415\n",
      "Epoch 184/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1993 - acc: 0.9299\n",
      "Epoch 00184: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1995 - acc: 0.9299 - val_loss: 0.5041 - val_acc: 0.8398\n",
      "Epoch 185/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1966 - acc: 0.9314\n",
      "Epoch 00185: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1964 - acc: 0.9315 - val_loss: 0.4979 - val_acc: 0.8399\n",
      "Epoch 186/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1981 - acc: 0.9314\n",
      "Epoch 00186: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1983 - acc: 0.9312 - val_loss: 0.4953 - val_acc: 0.8422\n",
      "Epoch 187/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1961 - acc: 0.9325\n",
      "Epoch 00187: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1961 - acc: 0.9325 - val_loss: 0.4984 - val_acc: 0.8406\n",
      "Epoch 188/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1987 - acc: 0.9323\n",
      "Epoch 00188: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1989 - acc: 0.9321 - val_loss: 0.5034 - val_acc: 0.8385\n",
      "Epoch 189/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1989 - acc: 0.9308\n",
      "Epoch 00189: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1989 - acc: 0.9309 - val_loss: 0.5017 - val_acc: 0.8395\n",
      "Epoch 190/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1975 - acc: 0.9312\n",
      "Epoch 00190: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1975 - acc: 0.9312 - val_loss: 0.4853 - val_acc: 0.8422\n",
      "Epoch 191/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2011 - acc: 0.9291\n",
      "Epoch 00191: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2010 - acc: 0.9291 - val_loss: 0.4983 - val_acc: 0.8413\n",
      "Epoch 192/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1969 - acc: 0.9313\n",
      "Epoch 00192: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1969 - acc: 0.9313 - val_loss: 0.4861 - val_acc: 0.8449\n",
      "Epoch 193/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1980 - acc: 0.9303\n",
      "Epoch 00193: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1981 - acc: 0.9303 - val_loss: 0.5047 - val_acc: 0.8368\n",
      "Epoch 194/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.2015 - acc: 0.9303\n",
      "Epoch 00194: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.2014 - acc: 0.9303 - val_loss: 0.4992 - val_acc: 0.8425\n",
      "Epoch 195/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1998 - acc: 0.9316\n",
      "Epoch 00195: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1996 - acc: 0.9316 - val_loss: 0.5048 - val_acc: 0.8439\n",
      "Epoch 196/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1989 - acc: 0.9303\n",
      "Epoch 00196: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1989 - acc: 0.9303 - val_loss: 0.4986 - val_acc: 0.8438\n",
      "Epoch 197/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1995 - acc: 0.9312\n",
      "Epoch 00197: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1994 - acc: 0.9312 - val_loss: 0.5053 - val_acc: 0.8398\n",
      "Epoch 198/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1960 - acc: 0.9328\n",
      "Epoch 00198: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1960 - acc: 0.9328 - val_loss: 0.4993 - val_acc: 0.8409\n",
      "Epoch 199/200\n",
      "400/400 [==============================] - ETA: 0s - loss: 0.1973 - acc: 0.9309\n",
      "Epoch 00199: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1973 - acc: 0.9309 - val_loss: 0.4985 - val_acc: 0.8412\n",
      "Epoch 200/200\n",
      "399/400 [============================>.] - ETA: 0s - loss: 0.1976 - acc: 0.9313\n",
      "Epoch 00200: val_acc did not improve from 0.84780\n",
      "400/400 [==============================] - 20s 50ms/step - loss: 0.1976 - acc: 0.9314 - val_loss: 0.5006 - val_acc: 0.8405\n"
     ]
    }
   ],
   "source": [
    "# Learning rate scheduler 함수\n",
    "def lr_scheduler(epoch) :\n",
    "    # epoch이 진행됨에 따라 learning rate를 조절함\n",
    "    learning_rate = LEARNING_RATE\n",
    "    if epoch >= 80 :\n",
    "        learning_rate = LEARNING_RATE * 0.1\n",
    "    if epoch >= 120 :\n",
    "        learning_rate = LEARNING_RATE * 0.01\n",
    "    return learning_rate\n",
    "\n",
    "# Keras 에서 제공하는 LearningRateScheduler를 통해 callback 생성\n",
    "lr = tf.keras.callbacks.LearningRateScheduler(lr_scheduler)\n",
    "   \n",
    "# Checkpoint 저장을 위한 callback\n",
    "# TRAINED_MODEL_PATH 에 'val_acc' 기준으로 최대값이 갱신될 때마다 저장하도록 구현\n",
    "save_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                filepath='trained_model\\checkpoint',\n",
    "                monitor='val_acc', verbose=1, save_best_only=True,\n",
    "                save_weights_only=False, mode='max', save_freq='epoch')\n",
    "\n",
    "# 필요한 callback 을 list 로 지정\n",
    "callback_list = [lr, save_callback]\n",
    "\n",
    "history = model.fit(datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='training'),\n",
    "                    # 학습에 사용할 데이터 : 미리 만들어둔 ImageDataGenerator pipeline에 x_train, y_train 입력하여 사용\n",
    "                    # subset = 'training' 으로 학습용 데이터라는 것을 pipeline에 알려주어야함\n",
    "                   validation_data=datagen.flow(x_train, y_train, batch_size=BATCH_SIZE, subset='validation'),\n",
    "                    # 검증에 사용할 데이터 : 미리 만들어둔 ImageDataGenerator pipeline에 x_train, y_train 입력하여 사용\n",
    "                    # subset = 'validation' 으로 검증용 데이터라는 것을 pipeline에 알려주어야함\n",
    "                    epochs=EPOCHS,              # epoch 횟수 입력\n",
    "                    shuffle=True,               # 매 epoch 학습 시작 전 데이터셋 무작위로 배치\n",
    "                    callbacks=[callback_list])  # 매 epoch이 종료될 때 호출할 callback 함수 지정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87330434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfgAAAHiCAYAAAAEZd6CAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAACTeElEQVR4nOzdd5hU1fnA8e+7vfdd2lKW3usCUhQQC1bsihW7xGg0MWqMiS3+NNEkxsSGvWM3GLGiCIpI770ssNTtvc3O+f1xZnaHZStbZnd5P88zz87cNu+9MzvvPeeee44YY1BKKaVU++Lj7QCUUkop1fQ0wSullFLtkCZ4pZRSqh3SBK+UUkq1Q5rglVJKqXZIE7xSSinVDmmCVwoQkS9E5JqmXtabRCRFRE5phu0uEJEbXM+vEJGv67PsMbxPNxHJFxHfY41VqeOZJnjVZrl+/N0Pp4gUeby+oiHbMsacYYx5vamXbY1E5F4RWVjN9DgRKRWRwfXdljHmbWPMaU0U1xEnJMaYPcaYMGNMeVNsv5r3ExHZKSIbm2P7SnmbJnjVZrl+/MOMMWHAHuAcj2lvu5cTET/vRdkqvQWMF5GkKtMvA9YZY9Z7ISZvOAlIAHqKyOiWfGP9TqqWoAletTsiMllEUkXkHhE5CLwqItEi8j8RSRORLNfzRI91PKudZ4rIjyLypGvZXSJyxjEumyQiC0UkT0S+FZFnROStGuKuT4yPiMhPru19LSJxHvOvEpHdIpIhIn+s6fgYY1KB74Crqsy6GnijrjiqxDxTRH70eH2qiGwWkRwR+Q8gHvN6ich3rvjSReRtEYlyzXsT6AZ85qqBuVtEeoiIcSdDEeksInNFJFNEtovIjR7bflBE3heRN1zHZoOIJNd0DFyuAf4LzHM999yvQSLyjeu9DonIfa7pviJyn4jscL3PChHpWjVW17JVvyc/icg/RSQDeLC24+Fap6uIfOz6HDJE5D8iEuCKaYjHcgkiUigi8XXsrzrOaIJX7VVHIAboDtyE/a6/6nrdDSgC/lPL+mOBLUAc8DfgZRGRY1j2HWApEAs8yNFJ1VN9YrwcuBZb8gwA7gIQkYHAc67td3a9X7VJ2eV1z1hEpB8w3BVvQ4+VextxwMfA/dhjsQOY4LkI8JgrvgFAV+wxwRhzFUfWwvytmreYA6S61r8I+D8ROdlj/rmuZaKAubXFLCIhrm287XpcJiIBrnnhwLfAl6736g3Md636W2AGcCYQAVwHFNZ2XDyMBXYCHYBHqeV4iG138D9gN9AD6ALMMcaUuvbxSo/tzgDmG2PS6hmHOl4YY/Shjzb/AFKAU1zPJwOlQFAtyw8HsjxeLwBucD2fCWz3mBcCGKBjQ5bFJkcHEOIx/y3grXruU3Ux3u/x+lfAl67nf8YmAPe8UNcxOKWGbYcAucB41+tHgf8e47H60fX8amCJx3KCTcg31LDd84BV1X2Grtc9XMfSD5v8yoFwj/mPAa+5nj8IfOsxbyBQVMuxvRJIc207CMgBznfNm+EZV5X1tgDTq5leEWstx2lPHZ93xfEAxrnjq2a5sdiTIXG9Xg5c0tz/Y/poew8twav2Ks0YU+x+ISIhIvKCqwo7F1gIREnNLbQPup8YY9wltLAGLtsZyPSYBrC3poDrGeNBj+eFHjF19ty2MaYAyKjpvVwxfQBc7aptuAJ4owFxVKdqDMbztYh0EJE5IrLPtd23sCX9+nAfyzyPabuxJVu3qscmSGq+1n0N8L4xxuH6nnxEZTV9V2ztQ3Vqm1eXIz77Oo5HV2C3McZRdSPGmF+w+zdZRPpjaxjmHmNMqh3TBK/aq6rDJP4O6AeMNcZEYBtYgcc14mZwAIhxVQe7da1l+cbEeMBz2673jK1jndeBS4BTgXDgs0bGUTUG4cj9/T/s5zLEtd0rq2yztqEt92OPZbjHtG7AvjpiOoqrPcHJwJUiclBsO42LgDNdlxn2Aj1rWH0v0Kua6QWuv56fdccqy1Tdv9qOx16gWy0nKK+7lr8K+NDzZFYpN03w6ngRjr2WnC0iMcADzf2Gxpjd2OrTB12No8YB5zRTjB8CZ4vIRNe15Iep+/97EZANzKby+m5j4vgcGCQiF7gS0+0cmeTCgXwgR0S6AL+vsv4hakisxpi9wGLgMREJEpGhwPXYUm9DXQVsxZ7EDHc9+mIvJ8zAXvvuJCJ3iEigiISLyFjXui8Bj4hIH7GGikissde/92FPGnxF5DqqPxHwVNvxWIo9YXpcREJd++zZnuEt4Hxskn/jGI6BOg5oglfHi6eAYCAdWIJtQNUSrsBeT80A/gK8B5TUsOxTHGOMxpgNwK3YRnIHgCxswqptHYNNDt05MkkcUxzGmHTgYuBx7P72AX7yWOQhYCT2evfn2AZ5nh4D7heRbBG5q5q3mIG91r0f+AR4wBjzbX1iq+Ia4FljzEHPB/A8cI3rMsCp2JOxg8A2YIpr3X8A7wNfY9swvIw9VgA3YpN0BjAIe0JSmxqPh7H3/p+DrX7fg/0sL/WYvxdYia0BWNTwQ6COB+5GGkqpFiAi7wGbjTHNXoOg2jcReQXYb4y539uxqNZJE7xSzUhsByqZwC7gNOBTYJwxZpU341Jtm4j0AFYDI4wxu7wbjWqtvFJFLyKviMhhEam2xyzXta2nxXZmsVZERrZ0jEo1kY7Y26XygaeBWZrcVWOIyCPAeuAJTe6qNl4pwYvISdgfvDeMMUf1ey0iZwK3YTuTGAv8yxgztupySimllKqeV0rwxpiF2GrLmkzHJn9jjFmCvQe3U8tEp5RSSrV9rbUVfReO7BQilSM7tFBKKaVULdr8iEYichO2r3FCQ0NH9e/f38sRKaWUUi1jxYoV6caYagcaaq0Jfh9H9oCVSA09VhljZmM76iA5OdksX768+aNTSimlWgER2V3TvNZaRT8XVx/ZInICkGOMOeDtoJRSSqm2wisleBF5FzviV5yIpGK7wvQHMMY8jx2f+UxgO3ZQhWu9EadSSinVVnklwRtjZtQx32C73VRKKaXUMWitVfRKKaWUagRN8EoppVQ7pAleKaWUaoc0wSullFLtkCZ4pZRSqh3SBK+UUkq1Q5rglVJKqXaotXZVq5RSrUK501DqcFLiKKfE4aTU4SQ6NICwwNp/PgtKHBSUOogLDcTHR46YZ4zhYG4xGfmlJMWFElrDtvJLHPj5CIF+PojYbRSVlnM4r5hyp8HXR4gJDSA8yJ+ycidZBaUEB/gSFuhXsXxWQSlbDuXRMSKI7rEhiAgljnL8fHzw9ancZn6JAx+B8CB/AvxqL/sZYyhxOMktKiO3uIzcYgeOckOnyCDiwwMr4i0uK6es3El4kH/FeoWl5fhW2adypyGnqIzMglJyikopcThxlNtp2YWlBPr7Eh0SQHSIP1EhAZSV2/eODg2gW0wIQf6+ABSXlZOSUUBOYRnlxpAQHkjPuLCK459XXMbOtAKyCksJ8POhpMxJanYRuUVlBPr5EBHkT5foYGJCAyhxOPHzEfp0CCPQz5f0/BJ2ZxQSExpAbFgAPiKUOpzszy4iLa+E+PBAEiICySt2cDi3hJSMAlKzCukSFUL/TuEIUFBSTo+4EBKjQ2o9vk1FE7xSqsUVl5XjcJqjkuTujAJ2pRcQHuRHWKA/4UF++Pv6kFNUhjGGrh4/5uVOw460fLYdyqeorByn0xARbNfJKSojo6CUzPxSMgpKyCgoJbuwlHKnQRDCgvyICrZJp6zcSVm5TViZBSUcziuhoMThSupOHE5T7T70jAslMsSf3KIy/H196BwVTKCfD5kFpezLLiI1qwiAAD8fIoL8KCgpx+F0Ehboh8NpyCt2VGyrY0QQUSH+RIX4Exnsj48Ia1Nz2JddVLFMoJ8Pfj5CQWn5UbEE+vlQ4nBWvPb3FQL9fBEgr6TyfbpEBSMC+7KL8PMREqNDKCkrZ39OccUyPgJdY0IIC/Qjq8AmwsFdIgkL9GPTgVxSs4rILS6jrLz64+Lehp+PD6XlNqbY0AA6RgaRmlVETlHZEXEH+PqQX+rA1Ly5WolAiL8vPj5yxDF1iwrxJzY0wPUdKKtmC7Xz9xViQwM5mFtc98LVxFZ1v/509kCun5jU4G0dCzHHelRbIR1sRqnKUlJZuZPC0nLS80twOA1DukTi7+tDQYmDzQdz8fPxIdDfhyA/X3xESM0q5GBuMV2igukWG8L+7CJ2HC7gQE4xh/KKOZxbQnp+CSEBvsSGBRIbGkBsaABhQX4E+PmwN7OIjQdyySoopcRRTmigH52jgnGUOzmYU0yJw0mgvy9ZBaXszSrEGAgN8KVDZBAdI4JIzy9h66H8WvdNBOLDAjFAfrGDorKjk11VEUF+xIUFEhXij5+vD8bY5JpdWIaPgL8rcfr7+hATGkBCeCDhQf42+fj5EOjnS6C/D4Gu5wF+PhzILmLdvhwKS8uJDPanxOFkX3YRZeVOYkJsMuvbIYyIYH/2ZReRW+QgLNAXXx97/AH6dAgjLiyQnWn5pGQUkl1YRm5RGdlFpZQ6nAzqHMnAzhEAlDiclJSVU1ZuiAsPICE8CH9foazckJFvP5ewQH9iQv0pLnOSUWC34TSGzlFB9O0Qzt6sIpbsyMDXR0iKC6W03MnujAICfH3oGR9GdIg/TgMZ+SXsSC+guLSc6NAA8osdrNuXQ1FZOf07htMjLpTIYH8iguzJVESwPxFBfviIcDCnmMN5xRSXOSlzOokI8sfXR0hJL2B/TjGJ0cF0jQ7BaQwlZbZGpMThJCLYn+gQf2JCA4gM9ifQzxd/XyEy2J/IEH9KypxkFZa6Svj2hCoiyJ+MghJ2phWQX+Kg3GmIDgkgKT6U2FBbwt6bVciKlCxyi8uICwukY2QQvRPscS91OAnw86FLVDBRIf4VNRKpWUVkFZYS6OdDUVk56/blcDCnmEGdI+idEEZ2oa1pMAZ8fYTOUcHEhweSllfCodxiIoL9iA+ztSWdo4LZn13EloN5+PoIIQG+JMWFkhAR1Oj/88r/CVlhjEmudp4meKXaphJHOTvTCth+OJ8daflsP5zPrvQCdmcUkl9ydEkmIsiPPh3CWZeaU1Gyqi934osLC6SorJyM/BIy8kuPKB36+wp9EsLpEBFIoJ8veSVl7M8uxs9H6BgZRLC/L8UOJ+FBfvSODyM4wJdDucUcyi3mYE4xwQG+nNy/A0MTIyksLSevuIy8Ygdl5U4iXaXtnWkFHMwpxscHgvx9GdQ5kgGdwgkP9MfHB3KK7DqRwbbUFh0agL+vNjVS7VdtCV6r6JVqA5xOwzebDrF0VyYHc4orErq7+lgEEqOD6RkXxugeMXSMDCLQz4cgf19iQwMoKzcs2HKYrYfzuWZ8d8YmxeLjA8Vlzorq8sSoYBIigtiXXcSezEI6RwbRJyGcjpFBNV6TLXGUU1RaTnGZk5jQgDqv3Ta3xGivvr1SrYomeKVauQVbDvOXzzex/XA+wf6+dIoKoltMCCf3T6B/pwh6x4fRMz604tp0Tc4a2qle79c7IazesQX6+RLoV/v7KqW8QxO8Uq3Yhv053PTmCrpGB/P0jBGcObgjflrlrJSqB03wSrUyxWXllDsNDqdh1lsriQkJ4P2bxxEbFujt0JRSbYgmeKVakDGG9Hx7G9X+7CLyix2UlDspczgpdpSzcncWi7alU+Jq4et0Gt7T5K6UOgaa4JVqYk6nYcP+XJamZFLudOIjwtZDeazem83ujMIj7leuqktUMDPGdKNDRBAHc4o4qW88o7pryzGlVMNpgleqEdw9em07lM/afdks3p7B4h3pZFXpUCMqxJ8RXaOY1DeeLlHBdIkOoUtUMBHB9h7yAF8f/H19CAnwrejdSymlGkMTvFK1cDoN2w7ns3RXBmtTczicV0JaXglp+SVkFtie0Tx1iAjk5P4dOLFPHON6xRIW6Eepw0lUiL8mbqVUi9IEr1QV+7OL+G7zYX7YmsaylMyK7i3jwgLoHBVM56gghnWNJCY0AD8fH/x9hZ7xYQzsFFHR17enUL18rpTyAk3w6ri1P7uIN37ezco9WYQH+uE0hi0H8yr65U6MDubUAR0YkxTD2KRYusYEaylcKdVmaIJX7VpqViFrU3PIKSpj++F8luzMYG9mIQF+PmQV2gFMhnWN4kBOMQYYkxTD4C6RTO4XT6/4ME3oSqk2SxO8ajfKnYbVe7NIzSqi3Gn4bvNh5q07gPsyeYCfD6O6RXPeiC44nIaYkAAuG9O1xYZuVEqplqQJXrU5OUVlvLVkN7vSCyguK6/oT339/pwjhoMMD/TjxhN7cs6wzsSGBRAbGuj1vtKVUqqlaIJXbUK507AmNZuvNxzi7V92k1fsoHNkEEH+vgT6+xLk78PJ/RNs/+wdI/D1ETpEBBISoF9x1UoUZUPOXogfAL7VfC+LsiFjO3QeCT41nIiWFYF/cPPFWFoAWSmu9wmBmKTK98tJhWUvQUE6nDALOgyqXM/phJIcCG6BPhv2rYSCNAiKtMfKL6D53xPAWQ4luS2zj01Ef/1Uq1JW7mRtajZLdmayJ6OQ/TlFHMgpZn92EYWl5fgInDqwA7dP7cOgzpHeDrdlFaRD1m6I6w3iC4c3QvYe+6Ps4wfx/SC+PwTWc7CYHd/B1q9gxFXQcbCdVlYEa+bAxv9C5+Ew4FzoNAx8fO28g+sgro/9kTu8GX78J4TEwsDpEBBq43GWgW8g+LkeoQkQ3R187ZCvOMshdx/4+ENEJ3CU2DjKCu123Akley8sfQHSt9vpA8+171Gd1BWw4WOY8BsIS7Cvv33AJoG4PjDk4iMTEthjGRpXGfeaOZB3AMqKIaKz3e9OwyCqm016Gz6x+9Nzin2PgjQ4tAFSl0NpPkR2hQ4D7XxHMax8HdK22G3lHoCNn9rp/iHQeQTE9oKIRJvMM3fB+o/BUQQdhsD4X0NJHuQfhuge9jNd8TrsmA8xPaH7BDAGCtPtutl7bJydR8Cg86HPaUeeJOQdhN0/wZ4ldrs+fhCZWLmP4Z1g02fw+e+g4PCRxyk4xsacdwAw4BcMq960341Jd9vj98ktsH8VnPkkjLgSVrwG6z6E4CgIjbfLBITa70JYvN2GKYf9qyF9C3QbZ2PeswS2fwMhcZAwwK4bGGZPikJi4dsHYckzlbF1PQGu+sQe149vstsKiYXYPtBjIoTE2GMjvvb/I6wDGKc9WUldCsW59n06DLZ/gyKgtNBuZ+cPkLHNbq+0EDbNtZ/HlPvgxLvs/8+yF+1JWc4+17EJhL5nwNBL7BCPeQft97rcAQEhEBQFnYbaz7QF6HjwyqvyisvYm1lESkYB32w8xLcbD1WMMR4fHkjnyCA6RgbRKTKYEd2iOKlPPNGhLXTG3prsWgTvXw1Fma4JAlTzvyu+0HWMLdlgICAMBpwN0Umw9j3YuQACI2yC3fVD5TrDZ9gS5O6foCjL/gBl77U/wn7BtiSXsQPKS2xi7jrG/hj7h9hp5aW1xy++9sdTfKE4x54EAIR3tj+Axdn2dUisTV7Ze+zJBNjkk5sKgZEw9iYYNsP+QGfvsfP3r4Tlr9r9jewGJ/4Wvr7f7ntQBGTuBKcDkk6yj/BOsPodu68+fhDXF9I224QZEmt/pPMO2n0He7xKcmveN/8Q+17uxOgbYD+f8hKI6AL5h+wxHHoxdB1rS6AHVtvjWZju2kYoDLnIJtvFT9sTiqrCOtgTlYztsPcXu82QWHvyFNnVrpO6FAoz7OeXMMiemB3aAJk7Kt8nJNbGln+Yiu9QUJT9DDoOtSdJgeH2RCBjh43fUWzfP/lau69LnoNfnrfHxTcQ/IIgob+NK7KrralIcJ1QFaTZk8OyAptcj/he+NjvQG5q5bTwTlCSD6V5Ry4bGGlrCcbcBEMvtScU834PvU62MaZvhQHn2O/xwbX2fWsjvvaz83yfgDB7suYWmuD6bgr0Pc2us/FT+z3L2WP3tctI+9fH156Eb/qs9u/LtMdtDUgTqW08eE3wyiv2Zhby7++28dHKfRWdxUQG+3PawA6c3D+BE3rGHp+JvDpr3oP//gpiesHke2zJ0+mwJdKYnvbH2FFik1Tqctj5vS1d+/jZ5GnK7XOnA6K62xK0ccK4X8Hgi+CHx2HlG3Ze17Ew8iqbZIuyYNs3cGCNLcnE9YXEZPse276BHhNgyv22unn7fFtiiewG/kE2IThK7N+8gzZRFOfYWAIj7AlDWZHdlq+/TVy+ATZxHN5o53caDsnX2ZLmnp/tvE1zjz4+4mN/9PufDR/dAPkHIWGgLdmFd4TCTFuiXPVWZaKLSITR19sf830roMsoGHUtRHW188uK4NBGm4gPrbc/4EMutvu4c4FNQGHx9vh3GGz3wVECqctgyxf2+I6aaUuNznJ78lBdtXy560RHfCtL3OVlcGCtrd0ITYDs3bb0nDim7uro8jKbYFa9aRN4eSnE9obu4+2j47DKOEry7b4dWGMTYlw/m3jcNS11KcqCX16wyXzSvbam4vv/szUdU+6DwRfa4+XmLLcnHwVptpYEY49PYLj9vu5cYD+HRFeuyt1nk3Vxto3xwBrof5atzXFb/ir87w6bqC97B3pNsdONsQm/rND1nXfA4U32BFl87UlO5+F2vZy99rM+tN7GFpZg1+kx0X5/jLGx+/rZ50tftCc3Y26y38+qn0lpIaT8aGsewjrYkwZff/tdK8q208I71O8Y14MmeOVVTqdhdWo2P+/IYOXuLDYfzGNfdhEBfj7MGN2VMUmxdI4KYlDnSG0EV5WjBP4xwCb3Kz+0Vc4NUZhpq9vTt9of3C6jjvzRdSt3VJ+AWpvDm+yPZ2xvm1xFbKk0NNbOz9kHq9+G0TfY6tmqSvLsCVJ8v/onMtW6bfqfvTzRaai3I/EKTfCqRTmdhn3ZRezJLGRNajbvL9tLSkYhAL0TwhjUOYJ+HcO5YEQiHSODvBxtK7f+Y/jwWrjiI+hzirejUUq1MrUl+DZwyq7agqyCUj5amcqX6w+y6UAuBaXlFfPG9Ijh9ql9mNQ3/vgc9rS0oObGYVU5nfDB1bZx0Vn/sFXLkd0qqx6VUqqevJLgRWQa8C/AF3jJGPN4lfndgNeBKNcy9xpj5rV0nKp27qS+cFs6S3ZkUFruZEiXSC4alciAThF0iw0hKS6UTpHNeFtPS3GW22u1Xcc0bL1DG+GlU+x17TP+euQ8Y46uLl/5mr2G6rbrB5jyR9uARymlGqDFE7yI+ALPAKcCqcAyEZlrjNnosdj9wPvGmOdEZCAwD+jR0rGqmn23+RD3fLSOtLwSesWHctW47lycnEj/jhHeDq15rHzDNua59kvoPq7m5bL32Nbuo66F4ZfDJzfbhma/PG9v1xp9g13OGHh2nK12P+0vdlruAfjmAdvSOzQBlr9iG5CNuLLZd08p1f54owQ/BthujNkJICJzgOmAZ4I3gDtTRAL7WzRCVcEYw8YDuazYncXOtAJSMgpISS8gJaOQ/h3DeXXmaAZ3acP3ox9Ya2+X6jnF3uZTk7Xv27/rP6w5wTud8Mkse/vO/lX2pODgWrj4dXtb1ry77a1D3cfZW5fSNtlH0iTban3ubbbV89lP2RbJ+Ydsa96Izk2+20qp9s8bCb4LsNfjdSowtsoyDwJfi8htQChQY+siEbkJuAmgW7duTRro8azU4eT1xSm8uWQ3ezJtA7mQAF96xIYyqEskV4ztztXjuxPo54WqY2Pg5dOg29jK0u+xbGPFa/DF3ZX3cHcaBpe8cXQnFDmpsGexvY1rw6cw7a/Vtzj/5TnY/aNN0PtX2Y5OhlwCg86z9+r+e5Rdpvs4eysb2PvTP/2VvW3m4Ho460nbAQrAzP/ZOJVS6hi01kZ2M4DXjDF/F5FxwJsiMtiYqr0kgDFmNjAbbCv6Fo6zXVm9N5tfdmZQVFbO3NX72ZlewLiescya3ItJfePpFBnUOkZX27XQduixf5W9FzXK48QuZ5+t1o7odOQ66z60HadM/bO9nv3Nn22HIr2mwumP2luvvvuLPXG48CV7z3ZZkb21bP1Hdhsn32/XS1loE7an3APw7UPQ70x7//OombY3qy6j7PygCNsT2+p3bKO7Hd/ZXucufAlePNl2PHL5+7YzDU+t4XgrpdokbyT4fUBXj9eJrmmergemARhjfhaRICAOqNKHomoKJY5y/vHNVmYv3FlRYOydEMar145mSr8E7wZXneUv2/vBy4pg0d/hnH/Z6cbAWxfazipu/M728AW2w4/PfuPqaCLT9ta1+GlIvh7OfMIm/IQBtmOLty6E18+pfK9t39h7r7uMgjE3ww9P2IRfVmQ7vDjvOXsysfsnm6Qn3VOZlHtMPDLugdNtX96bP4fdi+11+o5D4IZvbdeckV2a/9gppY4b3kjwy4A+IpKETeyXAZdXWWYPMBV4TUQGAEFAHf0OqoZyOg2frd3PU99uY1d6ATPGdOPu0/sRHuSHn28r7XAm76BNkGNvsZ3ArHgVJv7WJvOD6+w1bYB3Z8D1X9leshY8bhu6jbjSXhcH6DutMrm7JQywJwbbvrGl610LbKke4PTHbA9tA862fZavestO3/K5bTi3b6XtOrRqf+eeuk+wiXz+wzYe961vnYY16SFSSinwQoI3xjhE5NfAV9hb4F4xxmwQkYeB5caYucDvgBdF5E5sg7uZpj31yONFOUVlPP/DDn7ZmcGu9AKyCsvo3zGc164dzeSWKq3nHYJ5d9mEnH/IVk0nnWjnHVxvr0HXNGLWyjdtt5PJ19n+r1e+Dj/8Dc57BtZ9YLtkvWA2fHQjvHomDLvMXmsffT2c8Td7f/mBNXDhy9Xfehbe0d7SBtB1tO0lbfnLtqoe7MAs6z6EiXfaRL97sSvBL7eJurbe0Xx8bV/ZK161/bl3n3DMh1ApperilWvwrnva51WZ9meP5xsB/fVrQoWlDuYs3cu/v9tGdlEZo3vEMG1wR8b3iuOsIZ3w8Wmha72lhfDuZbbf9L6nw/bvbL/ZSSfakbeenwjdToArP6rsHKa00PbFvucX2yd3zymVDdHG3gyL/2MHwVj/kb2m7k7G3/0FvrrP9n3urjo/5cGGxTvuV/bh1mMC/PGgbWSXvccm+PIye9LgvgWuNgOn2wTfdWz9R31TSqlj0Fob2akmUFDiYGlKJj9tS+eDFankFJUxvlcsfzxrQO1DrRZl2+rvqgMibPrMXkPuf7YdlnLvLza5jbu19pJr1m47zGNUNzuQyP5VdmCI/mfCf2+FjXPt4BOr37YN5Pb+Au9cCjPetYNBfHQDbJlnG61F97DXrt1OutvewjbnCjvIyCkP2emDL4SB59tr4wGhdljQpuJuQd99vD2p2Py5rXLvMrLudXucaNsADL2k6eJRSqlqaIJvp37ZmcEtb60gq7AMf19hav8O3HhSEqO6VzMAR1WfzrKJ+LZVR44pvXQ2pPxkR33ydGg9nP8C7F1qR/2a8JvK6u+yInjvCkjbakfYcpbB6f9nkzvYJLzqLdj2tR01re/pdjzrj2+CJ/vZQUH2r4QznrBDhVYVFGGT+qe32Gvg/c6onOfjU1n13xzcVeyLn7Z/u1TbHfSRfP3glkXNF5NSSrlogm9njDF8sDyVP366jm4xITw9YwTJ3WMIDqjn/eqFmTbZOh229OtOkKWFdvzvE2bZ69oZ220189r34dsHbIcx6VvssonJtjc2Y+B/v7XX2i//AHpOtkM/hnlc6+85yY5F/fUfbQl8+OX2OnVML1j1hh0J7cTfVZ/c3YZeakvSMT1btto7rh8Ex9gubEPijrxdTymlvEwTfDuSkl7AA3M38MPWNCb0juXZK0YRGVxD1bmj1N46FtnF3t/ttvl/Nrn7+NlGZO4Ev2ex7RCm5xR7a1fHIXb6xDvsmMtLnrPXuX98CjbPswl+61ew5h07VrT7/u6wKg35fP1ty/RVb9lk2ed0Oz1xlH24b4GrjY+PHUq1pfn4QLdxtiV9YrLes66UalVa6b1QqiGMMby1ZDenP7WQFbuzeOCcgbx+7Ziak3t5mR2CdM07sPBJe03cbcMntne1oZfBxk9tyR1gx/e2J7fu44/e3pT74N499m/PyTbhGQPLXoTwznDS72vfgUHn279DLwG/gIbuvne5j4e7QxullGolNMG3YY5yJwu3pnH968u5/9P1jO0Zy/zfTeLaCUm138f+2R22pH7ynyAkFr68zybkgnTY+YNNuMNn2I5hNn9u19m5wFbJB4RUv0136bX/mbZ1+dYvYft8e8tZdd26ekqabGsRJtzRoP1vFXqfYk98eupwrkqp1kWr6NuotanZ3PTGCg7mFhMe6McfzxzA9ROT6r7dbevXsPotOPEuOOkuCI6Gz38LP//Htp435TD4AjsoSmQ3WPqCbR1+aL3t5rUufc8A7oD//tom/RFX1b2Or1/dpfzWKqE/3LvXdoKjlFKtiCb4NujHbenc/OZyokMDeP7KUUzuF0+Qfz0a0ZUWwOe/s720TbrHTht5DSx/Fb52XYeP6wsdBtvkPOn3MPd2eN51Hb5q/+vVCe9gr0enLrPX06O61r1OW6fJXSnVCmmCb0PKnYYXFu7gn99spVd8GK9fN4YOEQ1ILgseh5w9dkxz97VuXz/bpevBdbaxXGyfyur2kVfb15/cBM4o6FjPLlX7nWkTfPK1dS+rlFKqWWiCbwOMMfy8I4Mnv97Cyj3ZnDWkE/93wZCaG9G5rX3f9q/ecYi9je3nZ2yJvep45gGhtve46nQfB7cutY3tfOrZZGPMjba1vLtFvFJKqRanCb6V251RwK/fWcW6fTnEhQXw1KXDmT6889HDtpYVwbPjYPK99j710gL45BbbEcy1X9pb4kJi4NSHGh6Ef3DNfcNXJzDcDuyilFLKazTBt2KpWYVc/uIvFJQ6ePyCIZw3okvN19q3z4esXbY72WGX2dHNTDmU5MGLU2z1+4Uv20Z1Siml2j29Ta6VSssr4fIXfyGvuIy3rh/LZWO61d6QbtNn9u+en+0tb6lL7esrPrD9u/c+pXIQFqWUUu2eluBbIUe5k1+/s5LDecW8e+MJDO5SzcAwJfm2YZy7g5UtX0BgJBRmQPo22LvMNpDrdTLcvtpW1WtPa0opddzQEnwr9MTXW/hlVyb/d/4QRnQKgsX/hpxUOzN9O7x2Nvy1O7w6zY7GtmshlOTY+9rBdiubugy6jrGvw+LBL9A7O6OUUsortATfiqzYnckrP6bw+boDXHlCNy4YmQiL/gHzH4JFf4fxt8FP/7L9xI+/3fY0t3S2HQQmIMy2Xv/pKduHfGE6JI729i4ppZTyEk3wrcTT87fxj2+2EhHkx6zJvbjjlD5QnGuHIu02zjaSm/8wJAy046RH9wCnE7L3wtYvYNAFtqV7t3G2G1qoLMErpZQ67miCbwVe/WkX//hmK+eP6MJfzhtMaKDrY1n8AhRlwWmPQsfBtl/43qfY6+lg70u/4AX4/C4Y9ys7zZ3gA8Jtj3VKKaWOS5rgveyjFak89NlGThvYgScuGlo5SEz2Xlj8H+g7zQ6bCraP+KqCIuHCFytfd3N1YpM4CnzqOQa8UkqpdkcTvBd9teEgd3+0lgm9Y3l6xgib3J3l8MPf7LV2gCl/bNhGOw2FsA7Qa2rTB6yUUqrN0ATvJT9tT+e2d1YxpEsks69KrrzHfc0c+OFxO2TrqQ9DVLeGbdjXH36zBny11bxSSh3PNMF7wao9Wdz4xnKS4kJ57drRldfcAda+B9FJcNGrx37fekO6lVVKKdUu6X3wLWzboTxmvrqM+PBA3rx+DFEhAZUzcw/Ye9qHXqKd0iillGoUTfAtqLDUwe/eXMh4Wc9b148loepQrxs+BgwMudgr8SmllGo/NMG3oAf+u4HJ2R/znPMhum6cffQCa9+HTsMhrk+Lx6aUUqp90QTfQv67eh8frEjl/Lh9dsK3D8BSj9vb0rbCgdVaeldKKdUktJFdC8gsKOWhzzYyPDGSHgWbYdgMKMqGeb+H2F7Qcwp8dR/4h8CQi7wdrlJKqXZAS/At4P/mbSK3qIy/nxKOFGVBtxPgoldsT3MfufqP3/4NTH0Awjt6O1yllFLtgCb4ZrZ4ezofrkjl5kk96VWy2U7skgwBIXDxa7aP+W8ftD3QjbnJm6EqpZRqRzTBN6PisnLu+2QdPWJDuO3kPrBvOfiHQsIAu0BCfzjnaXvf+7n/sX3LK6WUUk3AKxlFRKaJyBYR2S4i99awzCUislFENojIOy0dY1P493fbSMko5NHzh9ie6lKXQ+cRR/YRP/Ri+M1qiOvttTiVUkq1Py3eyE5EfIFngFOBVGCZiMw1xmz0WKYP8AdggjEmS0QSWjrOxtpyMI8XftjJhSMTmdA7DsqK4eC6ylHflFJKqWbkjRL8GGC7MWanMaYUmANMr7LMjcAzxpgsAGPM4RaOsVGcTsO9H68lPMiPP57lqo4/uA6cZfb6u1JKKdXMGpXgReQcEWnoNroAez1ep7qmeeoL9BWRn0RkiYhMa0ycLe3tX3azak82fzp7IDGhrq5oU5fav4ma4JVSSjW/xpbgLwW2icjfRKR/UwTk4gf0ASYDM4AXRSSqugVF5CYRWS4iy9PS0powhGNzMKeYv365hYm94zh/hMd5y4ZPIGEgRHT2XnBKKaWOG41K8MaYK4ERwA7gNRH52ZVww2tZbR/Q1eN1omuap1RgrjGmzBizC9iKTfjVxTDbGJNsjEmOj48/5n1pCsYY/vjJOsrKnTx6/mDEPWBM+nZIXWY7uFFKKaVaQKOvwRtjcoEPsdfSOwHnAytF5LYaVlkG9BGRJBEJAC4D5lZZ5lNs6R0RicNW2e9sbKzN7a1f9jB/82HuOb0f3Te+AO9dBWVFsHYOiI92Q6uUUqrFNKoVvYicC1wL9AbeAMYYYw6LSAiwEfh31XWMMQ4R+TXwFeALvGKM2SAiDwPLjTFzXfNOE5GNQDnwe2NMRmNibW7bD+fx6OcbmdQnlmvznoOlrsFk5gbBniW2O9qITt4NUiml1HGjsbfJXQj80xiz0HOiMaZQRK6vaSVjzDxgXpVpf/Z4boDfuh6tnjGG+z5ZT7C/L890/Q5ZPBvG/RoCI2DB/9mFTnnAu0EqpZQ6rjQ2wT8IHHC/EJFgoIMxJsUYM7+R224zFmxJY+muTB6ZPoiwNY9At/Fw2l/szLTNsHsx9DvTu0EqpZQ6rjT2GvwHgNPjdblr2nHD6TT89cvNdI8N4bJhUXBoPSSdCCL2cdErcPtK2/e8Ukop1UIam+D9XJ3VAOB6HtDIbbYpn6/axe6Dafz21L7471sOxgndx1cuIAIBod4LUCml1HGpsQk+zdXQDgARmQ6kN3KbbYYxhg5f3MDnIQ9zzpBOsGcx+PhB4mhvh6aUUuo419hr8LcAb4vIfwDB9lB3daOjaiN2rlrAGMcK+2LX9/Zae6dhWmJXSinldY1K8MaYHcAJIhLmep3fJFG1EY4FT5BlwogMDcbnp3/BvhU6prtSSqlWodGjyYnIWcAgIMjdc5sx5uHGbre1K01dRb/cn/gs7jrOGZwAPzxuZ3hef1dKKaW8pLGDzTyP7Y/+NmwV/cVA9yaIq9U7/PU/yTXBRE/5NSRfBz7+dka3cd4NTCmllKLxjezGG2OuBrKMMQ8B47DdyrZ7zgPrWOsziHEDe0J4Bxh5tb3/PSTG26EppZRSja6iL3b9LRSRzkAGtj/6dm1PRiERpYcI6zQCXx/XgDJn/d27QSmllFIeGluC/8w1jOsTwEogBXinkdts9d7/eTNRUkDPXv0qJ7o7tlFKKaVagWNO8CLiA8w3xmQbYz7CXnvv79mnfHtU4ijnp5VrAYhI6OHdYJRSSqkaHHOCN8Y4gWc8XpcYY3KaJKpW7It1BwkpPmhfRHbxbjBKKaVUDRpbRT9fRC4UOX7qpt9fvpchYa7b/SM0wSullGqdGpvgb8YOLlMiIrkikiciuU0QV6uUX+JgWUomE+JdbQsjOns3IKWUUqoGje3JLrypAmkLluzIoKzc0Dc4B0ITwC/Q2yEppZRS1WpUgheRk6qbboxZ2JjttlaLtqUR7O9LvDNdS+9KKaVatcbeB/97j+dBwBhgBXByI7fbKi3als4JPWPwydsPsb29HY5SSilVo0ZdgzfGnOPxOBUYDGQ1TWity97MQnamF3Bin3jI2acN7JRSSrVqjW1kV1UqMKCJt9kqLNpmh7mf3D0ASvP0FjmllFKtWmOvwf8bMK6XPsBwbI927c6ibWl0jgwiKSDbTtASvFJKqVassdfgl3s8dwDvGmN+auQ2Wx1jDL/symRKvwQk94CdGJno3aCUUkqpWjQ2wX8IFBtjygFExFdEQowxhY0PrfXYnVFIZkEJI7tHQe4qO1FL8EoppVqxRvdkBwR7vA4Gvm3kNludlXuyeNH/H5y78XeQsQPEB8Lb/aB5Siml2rDGluCDjDH57hfGmHwRCWnkNludA5t/4QLfFbAb2PMdhHUE38YeOqWUUqr5NLYEXyAiI90vRGQUUNTIbbY6PVPeo0QC4ZSHwJRrC3qllFKtXmOLoXcAH4jIfkCAjsCljQ2qNSnMzWRSyQK2djidIRPvgKiuEBjp7bCUUkqpWjW2L/plItIf6OeatMUYU9b4sFqPQ4teI0lKKB5+nZ0w+ELvBqSUUkrVQ6Oq6EXkViDUGLPeGLMeCBORXzVNaK1D2KY5rHb2pPewCd4ORSmllKq3xl6Dv9EYk+1+YYzJAm5s5DZbD0cp0fnb2RA4kujQAG9Ho5RSStVbYxO8r4iI+4WI+ALtJxNm7sCPcsrj+tW9rFJKKdWKNDbBfwm8JyJTRWQq8C7wRV0ricg0EdkiIttF5N5alrtQRIyIJDcyzmNiDm0EoCy2vzfeXimllDpmjW1Ffw9wE3CL6/VabEv6GrlK+c8Ap2IHp1kmInONMRurLBcO/Ab4pZExHrOS/RvwN4JPXB9vhaCUUkodk8YOF+vEJuAU7FjwJwOb6lhtDLDdGLPTGFMKzAGmV7PcI8BfgeLGxNgYjoMbSTEdiYmK8FYISiml1DE5pgQvIn1F5AER2Qz8G9gDYIyZYoz5Tx2rdwH2erxOdU3z3P5IoKsx5vNjia+p+KZvZptJJCE8yJthKKWUUg12rCX4zdjS+tnGmInGmH8D5U0RkIj4AP8AflfP5W8SkeUisjwtLa0pQrDKignK280Wk0hCRGDTbVcppZRqAcea4C8ADgDfi8iLrgZ2Usc6bvuArh6vE13T3MKBwcACEUkBTgDm1tTQzhgz2xiTbIxJjo+Pb+Bu1CJjG4KTbc5EEsI1wSullGpbjinBG2M+NcZcBvQHvsd2WZsgIs+JyGl1rL4M6CMiSSISAFwGzPXYdo4xJs4Y08MY0wNYApxrjFle/eaayeHNAOz27UZYoA4so5RSqm1pbCO7AmPMO8aYc7Al8VXYlvW1reMAfg18hW2Q974xZoOIPCwi5zYmniZ1eCPl+FIQ1gOPW/2VUkqpNqHJiqauXuxmux51LTsPmFdl2p9rWHZyU8TXYGmb2e/XhZiIMK+8vVJKKdUYje3opv06vIkddNUGdkoppdokTfA1OeFXfOCYqLfIKaWUapM0wdegeOT1fF48jHhtQa+UUqoN0gRfg8O5JQCa4JVSSrVJmuBrcDjP9pCr98ArpZRqizTB1yAtz5bg9Rq8UkqptkgTfA0OuxO8tqJXSinVBmmCr8HhvGJ8fYSYkABvh6KUUko1mCb4GhzOLSEuLAAfH+3FTimlVNujCb4Gh/NK9Pq7UkqpNksTfA3S8kq0Bb1SSqk2SxN8DQ7nlWgDO6WUUm2WjoNag+/vmoSj3Hg7DKWUUuqYaIKvQXiQv7dDUEoppY6ZVtErpZRS7ZAmeKWUUqod0gSvlFJKtUOa4JVSSql2SBO8Ukop1Q5pgldKKaXaIU3wSimlVDukCV4ppZRqhzTBK6WUUu2QJnillFKqHdIEr5RSSrVDmuCVUkqpdkgTvFJKKdUOaYJXSiml2iFN8EoppVQ7pAleKaWUaoe8kuBFZJqIbBGR7SJybzXzfysiG0VkrYjMF5Hu3ohTKaWUaqtaPMGLiC/wDHAGMBCYISIDqyy2Ckg2xgwFPgT+1rJRKqWUUm2bN0rwY4DtxpidxphSYA4w3XMBY8z3xphC18slQGILx6iUUkq1ad5I8F2AvR6vU13TanI98EWzRqSUUkq1M37eDqA2InIlkAxMqmWZm4CbALp169ZCkSmllFKtmzdK8PuArh6vE13TjiAipwB/BM41xpTUtDFjzGxjTLIxJjk+Pr7Jg1VKKaXaIm+U4JcBfUQkCZvYLwMu91xAREYALwDTjDGHWz5EpZTyjrKyMlJTUykuLvZ2KKoVCQoKIjExEX9//3qv0+IJ3hjjEJFfA18BvsArxpgNIvIwsNwYMxd4AggDPhARgD3GmHNbOlallGppqamphIeH06NHD1y/f+o4Z4whIyOD1NRUkpKS6r2eV67BG2PmAfOqTPuzx/NTWjwopZRqBYqLizW5qyOICLGxsaSlpTVoPe3JTimlWhlN7qqqY/lOaIJXSilVISMjg+HDhzN8+HA6duxIly5dKl6XlpbWuu7y5cu5/fbb63yP8ePHN1W4ANxxxx106dIFp9PZpNtt61r1bXJKKaVaVmxsLKtXrwbgwQcfJCwsjLvuuqtivsPhwM+v+tSRnJxMcnJyne+xePHiJokVwOl08sknn9C1a1d++OEHpkyZ0mTb9lTbfrdWWoJXSilVq5kzZ3LLLbcwduxY7r77bpYuXcq4ceMYMWIE48ePZ8uWLQAsWLCAs88+G7AnB9dddx2TJ0+mZ8+ePP300xXbCwsLq1h+8uTJXHTRRfTv358rrrgCYwwA8+bNo3///owaNYrbb7+9YrtVLViwgEGDBjFr1izefffdiumHDh3i/PPPZ9iwYQwbNqzipOKNN95g6NChDBs2jKuuuqpi/z788MNq4zvxxBM599xzGTjQ9qh+3nnnMWrUKAYNGsTs2bMr1vnyyy8ZOXIkw4YNY+rUqTidTvr06VNx3dzpdNK7d+8GX0dvjLZ1OqKUUseRhz7bwMb9uU26zYGdI3jgnEENXi81NZXFixfj6+tLbm4uixYtws/Pj2+//Zb77ruPjz766Kh1Nm/ezPfff09eXh79+vVj1qxZR93mtWrVKjZs2EDnzp2ZMGECP/30E8nJydx8880sXLiQpKQkZsyYUWNc7777LjNmzGD69Oncd999lJWV4e/vz+23386kSZP45JNPKC8vJz8/nw0bNvCXv/yFxYsXExcXR2ZmZp37vXLlStavX1/Rev2VV14hJiaGoqIiRo8ezYUXXojT6eTGG2+siDczMxMfHx+uvPJK3n77be644w6+/fZbhg0bRkv216IleKWUUnW6+OKL8fX1BSAnJ4eLL76YwYMHc+edd7Jhw4Zq1znrrLMIDAwkLi6OhIQEDh06dNQyY8aMITExER8fH4YPH05KSgqbN2+mZ8+eFUm1pgRfWlrKvHnzOO+884iIiGDs2LF89dVXAHz33XfMmjULAF9fXyIjI/nuu++4+OKLiYuLAyAmJqbO/R4zZswRt6Y9/fTTDBs2jBNOOIG9e/eybds2lixZwkknnVSxnHu71113HW+88QZgTwyuvfbaOt+vKWkJXimlWqljKWk3l9DQ0Irnf/rTn5gyZQqffPIJKSkpTJ48udp1AgMDK577+vricDiOaZmafPXVV2RnZzNkyBAACgsLCQ4OrrE6vyZ+fn4VDfScTucRjQk993vBggV8++23/Pzzz4SEhDB58uRaOyTq2rUrHTp04LvvvmPp0qW8/fbbDYqrsbQEr5RSqkFycnLo0sWOEfbaa681+fb79evHzp07SUlJAeC9996rdrl3332Xl156iZSUFFJSUti1axfffPMNhYWFTJ06leeeew6A8vJycnJyOPnkk/nggw/IyMgAqKii79GjBytWrABg7ty5lJWVVft+OTk5REdHExISwubNm1myZAkAJ5xwAgsXLmTXrl1HbBfghhtu4MorrzyiBqSlaIJXSinVIHfffTd/+MMfGDFiRINK3PUVHBzMs88+y7Rp0xg1ahTh4eFERkYesUxhYSFffvklZ511VsW00NBQJk6cyGeffca//vUvvv/+e4YMGcKoUaPYuHEjgwYN4o9//COTJk1i2LBh/Pa3vwXgxhtv5IcffmDYsGH8/PPPR5TaPU2bNg2Hw8GAAQO49957OeGEEwCIj49n9uzZXHDBBQwbNoxLL720Yp1zzz2X/Pz8Fq+eBxB3i8X2IDk52SxfvtzbYSil1DHbtGkTAwYM8HYYXpefn09YWBjGGG699Vb69OnDnXfe6e2wGmz58uXceeedLFq0qNHbqu67ISIrjDHV3puoJXillFKtzosvvsjw4cMZNGgQOTk53Hzzzd4OqcEef/xxLrzwQh577DGvvL+W4JVSqhXREryqiZbglVJKKaUJXimllGqPNMErpZRS7ZAmeKWUUqod0gSvlFKqwpQpUyq6e3V76qmnKrp9rc7kyZNxN3A+88wzyc7OPmqZBx98kCeffLLW9/7000/ZuHFjxes///nPfPvttw2IvnbH27CymuCVUkpVmDFjBnPmzDli2pw5c2od8MXTvHnziIqKOqb3rprgH374YU455ZRj2lZVVYeVbS7N0fHPsdIEr5RSqsJFF13E559/XtEfe0pKCvv37+fEE09k1qxZJCcnM2jQIB544IFq1+/Rowfp6ekAPProo/Tt25eJEydWDCkL9h730aNHM2zYMC688EIKCwtZvHgxc+fO5fe//z3Dhw9nx44dRwzjOn/+fEaMGMGQIUO47rrrKCkpqXi/Bx54gJEjRzJkyBA2b95cbVzH47CyOtiMUkq1Vl/cCwfXNe02Ow6BMx6vcXZMTAxjxozhiy++YPr06cyZM4dLLrkEEeHRRx8lJiaG8vJypk6dytq1axk6dGi121mxYgVz5sxh9erVOBwORo4cyahRowC44IILuPHGGwG4//77efnll7nttts499xzOfvss7nooouO2FZxcTEzZ85k/vz59O3bl6uvvprnnnuOO+64A4C4uDhWrlzJs88+y5NPPslLL710VDzH47CyWoJXSil1BM9qes/q+ffff5+RI0cyYsQINmzYcER1elWLFi3i/PPPJyQkhIiICM4999yKeevXr+fEE09kyJAhvP322zUON+u2ZcsWkpKS6Nu3LwDXXHMNCxcurJh/wQUXADBq1KiKAWo8Ha/DymoJXimlWqtaStrNafr06dx5552sXLmSwsJCRo0axa5du3jyySdZtmwZ0dHRzJw5s9ahUmszc+ZMPv30U4YNG8Zrr73GggULGhWve8jZmoabPV6HldUSvFJKqSOEhYUxZcoUrrvuuorSe25uLqGhoURGRnLo0CG++OKLWrdx0kkn8emnn1JUVEReXh6fffZZxby8vDw6depEWVnZEcksPDycvLy8o7bVr18/UlJS2L59OwBvvvkmkyZNqvf+HK/DymqCV0opdZQZM2awZs2aigQ/bNgwRowYQf/+/bn88suZMGFCreuPHDmSSy+9lGHDhnHGGWcwevToinmPPPIIY8eOZcKECfTv379i+mWXXcYTTzzBiBEj2LFjR8X0oKAgXn31VS6++GKGDBmCj48Pt9xyS73243geVlYHm1FKqVZEB5s5PtVnWNmGDjaj1+CVUkopL3r88cd57rnnmuzau5tW0SullFJedO+997J7924mTpzYpNvVBK+UUkq1Q5rglVKqlWlPbaNU0ziW74QmeKWUakWCgoLIyMjQJK8qGGPIyMggKCioQetpIzullGpFEhMTSU1NbZK+yFX7ERQURGJiYoPW8UqCF5FpwL8AX+AlY8zjVeYHAm8Ao4AM4FJjTEpLx6mUUi3N39//iC5PlTpWLV5FLyK+wDPAGcBAYIaIDKyy2PVAljGmN/BP4K8tG6VSSinVtnnjGvwYYLsxZqcxphSYA0yvssx04HXX8w+BqSIiLRijUkop1aZ5I8F3AfZ6vE51Tat2GWOMA8gBYlskOqWUUqodaPON7ETkJuAm18t8EdnShJuPA9KbcHvepPvSOum+tE66L62T7svRutc0wxsJfh/Q1eN1omtadcukiogfEIltbHcUY8xsYHYzxImILK+pj9+2RvelddJ9aZ10X1on3ZeG8UYV/TKgj4gkiUgAcBkwt8oyc4FrXM8vAr4zelOoUkopVW8tXoI3xjhE5NfAV9jb5F4xxmwQkYeB5caYucDLwJsish3IxJ4EKKWUUqqevHIN3hgzD5hXZdqfPZ4XAxe3dFzVaJaqfy/RfWmddF9aJ92X1kn3pQHa1XjwSimllLK0L3qllFKqHdIEXw0RmSYiW0Rku4jc6+14GkJEuorI9yKyUUQ2iMhvXNMfFJF9IrLa9TjT27HWh4ikiMg6V8zLXdNiROQbEdnm+hvt7TjrIiL9PI79ahHJFZE72srnIiKviMhhEVnvMa3az0Gsp13/P2tFZKT3Ij9aDfvyhIhsdsX7iYhEuab3EJEij8/nea8FXo0a9qXG75SI/MH1uWwRkdO9E3X1atiX9zz2I0VEVrumt/bPpabf4Zb9nzHG6MPjgW34twPoCQQAa4CB3o6rAfF3Aka6nocDW7FdAj8I3OXt+I5hf1KAuCrT/gbc63p+L/BXb8fZwH3yBQ5i719tE58LcBIwElhf1+cAnAl8AQhwAvCLt+Ovx76cBvi5nv/VY196eC7X2h417Eu13ynX78AaIBBIcv3O+Xp7H2rblyrz/w78uY18LjX9Drfo/4yW4I9Wn650Wy1jzAFjzErX8zxgE0f3FNjWeXZl/DpwnvdCOSZTgR3GmN3eDqS+jDELsXe0eKrpc5gOvGGsJUCUiHRqkUDrobp9McZ8bWyvmQBLsP1ztHo1fC41mQ7MMcaUGGN2Aduxv3etQm374uqq/BLg3RYN6hjV8jvcov8zmuCPVp+udNsEEekBjAB+cU36tav655W2UK3tYoCvRWSF2F4LAToYYw64nh8EOngntGN2GUf+ULXFzwVq/hza+v/QddjSlFuSiKwSkR9E5ERvBdVA1X2n2vLnciJwyBizzWNam/hcqvwOt+j/jCb4dkpEwoCPgDuMMbnAc0AvYDhwAFvd1RZMNMaMxI4+eKuInOQ509j6rTZzK4jYzp3OBT5wTWqrn8sR2trnUBMR+SPgAN52TToAdDPGjAB+C7wjIhHeiq+e2sV3qooZHHlS3CY+l2p+hyu0xP+MJvij1acr3VZNRPyxX6q3jTEfAxhjDhljyo0xTuBFWlHVXG2MMftcfw8Dn2DjPuSuvnL9Pey9CBvsDGClMeYQtN3PxaWmz6FN/g+JyEzgbOAK148vrursDNfzFdjr1n29FmQ91PKdaqufix9wAfCee1pb+Fyq+x2mhf9nNMEfrT5d6bZarmtVLwObjDH/8JjueT3nfGB91XVbGxEJFZFw93NsQ6j1HNmV8TXAf70T4TE5oiTSFj8XDzV9DnOBq10tg08AcjyqJVslEZkG3A2ca4wp9JgeLyK+ruc9gT7ATu9EWT+1fKfmApeJSKCIJGH3ZWlLx3cMTgE2G2NS3RNa++dS0+8wLf0/4+3Whq3xgW3RuBV7VvhHb8fTwNgnYqt91gKrXY8zgTeBda7pc4FO3o61HvvSE9vqdw2wwf1ZYIcOng9sA74FYrwdaz33JxQ7aFKkx7Q28blgT0oOAGXY64PX1/Q5YFsCP+P6/1kHJHs7/nrsy3bsNVD3/8zzrmUvdH33VgMrgXO8HX899qXG7xTwR9fnsgU4w9vx17UvrumvAbdUWba1fy41/Q636P+M9mSnlFJKtUNaRa+UUkq1Q5rglVJKqXZIE7xSSinVDmmCV0oppdohTfBKKaVUO6QJXimllGqHNMErpZRS7ZAmeKUaSUS+EJFr6l6yYct6k2vs7VOaYbsLROQG1/MrROTr+ix7DO/TTUTy3b2dKXU80gSvjkuuH3/3wykiRR6vr2jItowxZxhjXq97yYYt2xqJyL0isrCa6XEiUioig+u7LWPM28aY05ooriNOSIwxe4wxYcaY8qbYfpX3MiLSu6m3q1RT0wSvjkuuH/8wY0wYsAfb1aV7mnskMfdAF6rSW8B4V1/mni4D1hlj2lJf+kq1a5rglfIgIpNFJFVE7hGRg8CrIhItIv8TkTQRyXI9T/RYx7PaeaaI/CgiT7qW3SUiZxzjskkislBE8kTkWxF5RkTeqiHu+sT4iIj85Nre1yIS5zH/KhHZLSIZYodMrZaxA358B1xVZdbVwBt1xVEl5pki8qPH61NFZLOI5IjIf7D9c7vn9RKR71zxpYvI2yIS5Zr3JtAN+MxVA3O3iPRwlbT9XMt0FpG5IpIpIttF5EaPbT8oIu+LyBuuY7NBRJJrOgY1EZFI1zbSXMfyfhHxcc3rLXbc8hxX/O+5pouI/FNEDotIroisa0gtiFK10QSv1NE6AjFAd+Am7P/Jq67X3YAi4D+1rD8WO5hHHPA34GURkWNY9h3saF+xwIMcnVQ91SfGy4FrgQQgALgLQEQGYscQvwro7Hq/apOyy+uesYhIP+zY4+/UM46juE42Pgbuxx6LHcAEz0WAx1zxDcAOrfkggDHmKo6shflbNW8xBzuASWfgIuD/RORkj/nnupaJwg7QUmfM1fg3EIkdJGkS9qTnWte8R4CvgWjssf23a/ppwEnYoU4jgUuwAxIp1Wia4JU6mhN4wNgxp4uMMRnGmI+MMYXGmDzgUewPeE12G2NedF3/fR3oBHRoyLIi0g0YDfzZGFNqjPmRWoYtrmeMrxpjthpjioD3sUkZbML7nzFmoTGmBPiT6xjU5BNXjONdr68GvjDGpB3DsXI7E9hgjPnQGFMGPAUc9Ni/7caYb1yfSRrwj3puFxHpij1ZuMcYU2yMWQ285Irb7UdjzDzX5/AmMKw+2/Z4D1/sZYo/GGPyjDEpwN+pPBEqw570dHbF8KPH9HCgPyDGmE2mlQ+tq9oOTfBKHS3NGFPsfiEiISLygqvaNRdYCERJzS20PROTe2zxsAYu2xnI9JgGdjjTatUzxoMezws9YursuW1jTAG1lCJdMX2Aa/xq4ArgjQbEUZ2qMRjP1yLSQUTmiMg+13bfwpb068N9LPM8pu0Guni8rnpsgqRh7S/iAH/Xdqt7j7uxtRBLXZcArgMwxnyHrS14BjgsIrNFJKIB76tUjTTBK3W0qmMo/w7oB4w1xkRgq1TB4xpxMzgAxIhIiMe0rrUs35gYD3hu2/WesXWs8zq2OvlUbAn0s0bGUTUG4cj9/T/s5zLEtd0rq2yztnGv92OPZbjHtG7Avjpiaoh0KkvpR72HMeagMeZGY0xn4GbgWXG1xDfGPG2MGQUMxFbV/74J41LHMU3wStUtHHstOVtEYoAHmvsNjTG7geXAgyISICLjgHOaKcYPgbNFZKKIBAAPU/dvwyIgG5gNzDHGlDYyjs+BQSJygavkfDu2LYRbOJAP5IhIF45Ogoew176PYozZCywGHhORIBEZClyPrQU4VgGubQWJSJBr2vvAoyISLiLdgd+630NELvZobJiFPSFxishoERkrIv5AAVBM7ZdHlKo3TfBK1e0pIBhbSlsCfNlC73sFMA5bXf4X4D2gpIZln+IYYzTGbABuxTaSO4BNQKl1rGOw1fLdXX8bFYcxJh24GHgcu799gJ88FnkIGAnkYE8GPq6yiceA+0UkW0TuquYtZgA9sKX5T7BtLL6tT2w12IA9kXE/rgVuwybpncCP2OP5imv50cAvIpKPbUvxG2PMTiACeBF7zHdj9/2JRsSlVAWx/6dKqdbOdWvVZmNMs9cgKKXaPi3BK9VKuapve4mIj4hMA6YDn3o5LKVUG6G9dCnVenXEVkXHYqvMZxljVnk3JKVUW6FV9EoppVQ7pFX0SimlVDukCV4ppZRqh9rVNfi4uDjTo0cPb4ehlFJKtYgVK1akG2Piq5vXrhJ8jx49WL58ubfDUEoppVqEiOyuaZ5W0SullFLtkCZ4pZRSqh3SBK+UUkq1Q+3qGrxSSqnalZWVkZqaSnFxcd0Lq1YjKCiIxMRE/P39672OJnillDqOpKamEh4eTo8ePbCj8qrWzhhDRkYGqampJCUl1Xs9raKvwd7MQg7m6BmuUqp9KS4uJjY2VpN7GyIixMbGNrjWRRN8DS58bjH//Gart8NQSqkmp8m97TmWz0wTfA0ig/3JKSrzdhhKKdWuZGRkMHz4cIYPH07Hjh3p0qVLxevS0tJa112+fDm33357ne8xfvz4Jol1wYIFnH322U2yLW/Qa/A1iArRBK+UUk0tNjaW1atXA/Dggw8SFhbGXXfdVTHf4XDg51d9akpOTiY5ObnO91i8eHGTxNrWaQm+BlqCV0qpljFz5kxuueUWxo4dy913383SpUsZN24cI0aMYPz48WzZsgU4skT94IMPct111zF58mR69uzJ008/XbG9sLCwiuUnT57MRRddRP/+/bniiitwj6A6b948+vfvz6hRo7j99tsbVFJ/9913GTJkCIMHD+aee+4BoLy8nJkzZzJ48GCGDBnCP//5TwCefvppBg4cyNChQ7nssssaf7AaQEvwNYgI9mfTgTxvh6GUUseF1NRUFi9ejK+vL7m5uSxatAg/Pz++/fZb7rvvPj766KOj1tm8eTPff/89eXl59OvXj1mzZh11G9mqVavYsGEDnTt3ZsKECfz0008kJydz8803s3DhQpKSkpgxY0a949y/fz/33HMPK1asIDo6mtNOO41PP/2Url27sm/fPtavXw9AdnY2AI8//ji7du0iMDCwYlpL0QRfAy3BK6Xau4c+28DG/blNus2BnSN44JxBDV7v4osvxtfXF4CcnByuueYatm3bhohQVlb9b/FZZ51FYGAggYGBJCQkcOjQIRITE49YZsyYMRXThg8fTkpKCmFhYfTs2bPilrMZM2Ywe/bsesW5bNkyJk+eTHy8Hd/liiuuYOHChfzpT39i586d3HbbbZx11lmcdtppAAwdOpQrrriC8847j/POO6/Bx6UxtIq+BpHB/uSXOHCUO70dilJKtXuhoaEVz//0pz8xZcoU1q9fz2effVbj7WGBgYEVz319fXE4HMe0TFOIjo5mzZo1TJ48meeff54bbrgBgM8//5xbb72VlStXMnr06GZ7/+poCb4GkcG2mie32EFMaICXo1FKqaZ3LCXtlpCTk0OXLl0AeO2115p8+/369WPnzp2kpKTQo0cP3nvvvXqvO2bMGG6//XbS09OJjo7m3Xff5bbbbiM9PZ2AgAAuvPBC+vXrx5VXXonT6WTv3r1MmTKFiRMnMmfOHPLz84mKimryfaqOJvgaRIXYBJ9TVKYJXimlWtDdd9/NNddcw1/+8hfOOuusJt9+cHAwzz77LNOmTSM0NJTRo0fXuOz8+fOPqPb/4IMPePzxx5kyZQrGGM466yymT5/OmjVruPbaa3E6ba3vY489Rnl5OVdeeSU5OTkYY7j99ttbLLkDiLtFYXuQnJxsmmo8+O82H+K615bzya/GM6JbdJNsUymlvG3Tpk0MGDDA22F4XX5+PmFhYRhjuPXWW+nTpw933nmnt8OqVXWfnYisMMZUe+9gs12DF5FXROSwiKyvYf7vRWS167FeRMpFJMY1L0VE1rnmNU3GbiB3Fb02tFNKqfbnxRdfZPjw4QwaNIicnBxuvvlmb4fU5Jqziv414D/AG9XNNMY8ATwBICLnAHcaYzI9FplijElvxvhqpQleKaXarzvvvLPVl9gbq9lK8MaYhUBmnQtaM4B3myuWYxHhbmSnCV4ppVQb5PXb5EQkBJgGePZiYICvRWSFiNxUx/o3ichyEVmelpbWZHFpCV4ppVRb5vUED5wD/FSlen6iMWYkcAZwq4icVNPKxpjZxphkY0yyu+OBphDo50uwv68meKWUUm1Sa0jwl1Glet4Ys8/19zDwCTDGC3ERGexPdqEmeKWUUm2PVxO8iEQCk4D/ekwLFZFw93PgNKDalvjNats3jPHfqSV4pZRqQlOmTOGrr746YtpTTz3FrFmzalxn8uTJuG+BPvPMM6vt0/3BBx/kySefrPW9P/30UzZu3Fjx+s9//jPffvttA6KvXmsdVrY5b5N7F/gZ6CciqSJyvYjcIiK3eCx2PvC1MabAY1oH4EcRWQMsBT43xnzZXHHW6LM7uLD8C03wSinVhGbMmMGcOXOOmDZnzpx6D/gyb968Y+4spmqCf/jhhznllFOOaVttQXO2op9hjOlkjPE3xiQaY142xjxvjHneY5nXjDGXVVlvpzFmmOsxyBjzaHPFWKvoHnQyhzTBK6VUE7rooov4/PPPKS0tBSAlJYX9+/dz4oknMmvWLJKTkxk0aBAPPPBAtev36NGD9HR7B/Wjjz5K3759mThxYsWQsmDvcR89ejTDhg3jwgsvpLCwkMWLFzN37lx+//vfM3z4cHbs2MHMmTP58MMPAdtj3YgRIxgyZAjXXXcdJSUlFe/3wAMPMHLkSIYMGcLmzZvrva/eHla2NVyDb52iu9Oh/KDeJqeUUk0oJiaGMWPG8MUXXwC29H7JJZcgIjz66KMsX76ctWvX8sMPP7B27doat7NixQrmzJnD6tWrmTdvHsuWLauYd8EFF7Bs2TLWrFnDgAEDePnllxk/fjznnnsuTzzxBKtXr6ZXr14VyxcXFzNz5kzee+891q1bh8Ph4LnnnquYHxcXx8qVK5k1a1adlwHc3MPKfvfdd6xevZply5bx6aefsnr16ophZdetW8e1114L2GFlV61axdq1a3n++efr2Hr9aF/0NYnuQaQjneLSgrqXVUqptuiLe+HguqbdZschcMbjtS7irqafPn06c+bM4eWXXwbg/fffZ/bs2TgcDg4cOMDGjRsZOnRotdtYtGgR559/PiEhIQCce+65FfPWr1/P/fffT3Z2Nvn5+Zx++um1xrNlyxaSkpLo27cvANdccw3PPPMMd9xxB2BPGABGjRrFxx9/XPcxoHUMK6sl+JpE97B/yg5SpkPGKqVUk5k+fTrz589n5cqVFBYWMmrUKHbt2sWTTz7J/PnzWbt2LWeddVaNw8TWZebMmfznP/9h3bp1PPDAA8e8HTf3kLNNMdxsSw4rqyX4mkR1B6CrHCanqIy4sMA6VlBKqTamjpJ2cwkLC2PKlClcd911FY3rcnNzCQ0NJTIykkOHDvHFF18wefLkGrdx0kknMXPmTP7whz/gcDj47LPPKvqTz8vLo1OnTpSVlfH2229XDD0bHh5OXl7eUdvq168fKSkpbN++nd69e/Pmm28yadKkRu1jaxhWVhN8TVwl+G6a4JVSqsnNmDGD888/v6JF/bBhwxgxYgT9+/ena9euTJgwodb1R44cyaWXXsqwYcNISEg4YsjXRx55hLFjxxIfH8/YsWMrkvpll13GjTfeyNNPP13RuA4gKCiIV199lYsvvhiHw8Ho0aO55ZZbjnrP2rTGYWV1uNiaGEP5XzrySsnJjLrpWUbqkLFKqXZAh4ttu1rNcLFtngil4V0rSvBKKaVUW6IJvhbOyO42wWt3tUoppdoYTfC18IlNIlHSyCks9XYoSimlVINogq9FQFwS4VJESV66t0NRSqkm057aXh0vjuUz0wRfC9+YJPs3O6Vy4tzb4as/eicgpZRqpKCgIDIyMjTJtyHGGDIyMggKCmrQenqbXG1ct8oF5O21r8vLYN2HkNDfezEppVQjJCYmkpqaSlpamrdDUQ0QFBR0xG149aEJvjZR3QDwy91tXx9YC2UFUJTtvZiUUqoR/P39SUpK8nYYqgVoFX1tAsPI840mJN+V4Pcstn+Ls70WklJKKVUfmuDrkBEzgvHOFWTk5MPun+3EomzQ61dKKaVaMU3wdcgbeBnxkkv6yrm2BC8+YMqh5Oj+jJVSSqnWotkSvIi8IiKHRWR9DfMni0iOiKx2Pf7sMW+aiGwRke0icm9zxVgfccPP5LCJosPyv0FRFnQ9wc7QanqllFKtWHOW4F8DptWxzCJjzHDX42EAEfEFngHOAAYCM0RkYDPGWauOUWF8xiSiCnbZCf3PtH+1oZ1SSqlWrNkSvDFmIZB5DKuOAbYbY3YaY0qBOcD0Jg2uAUSEVbFn2RfhnaDTcPu8KMtbISmllFJ18vY1+HEiskZEvhCRQa5pXYC9HsukuqZ5TXjiAOYzFjP4QgiOshO1il4ppVQr5s374FcC3Y0x+SJyJvAp0KehGxGRm4CbALp169akAbr1SQjn+uLfsHT8VBKcrm5rtYpeKaVUK+a1ErwxJtcYk+96Pg/wF5E4YB/Q1WPRRNe0mrYz2xiTbIxJjo+Pb5ZY+3YIB2DboXwIirITtQSvlFKqFfNagheRjiIirudjXLFkAMuAPiKSJCIBwGXAXG/FCdC3QxgAWw/lQUAo+PjpNXillFKtWrNV0YvIu8BkIE5EUoEHAH8AY8zzwEXALBFxAEXAZcaOfuAQkV8DXwG+wCvGmA3NFWd9xIcHEhnsz9ZD+SBiS/FaRa+UUqoVa7YEb4yZUcf8/wD/qWHePGBec8R1LESE/h3D2Xgg104IjtYqeqWUUq2at1vRtxnDukaxaX8upQ6nbUmvVfRKKaVaMU3w9TQ0MZLScidbDuZpFb1SSqlWTxN8PQ1LjAJgdWq2LcFrFb1SSqlWTBN8PSVGBxMTGsDavdn2GryW4JVSSrVimuDrSUQYmhjJ2tQcW0VfnANOp7fDUkoppaqlCb4BhiVGse1wHiX+EYCBkhxvh6SUUkpVSxN8AwzrGonTQGpRgJ2g1fRKKaVaKU3wDTDU1dBue56/naC3yimllGqlNME3QFxYIF2igtmQ5Tps2pJeKaVUK6UJvoHG9ozhp30O+0Kr6JVSSrVSmuAbaGr/DqQWBdoXWoJXSinVSmmCb6CT+sZR4GuHj9Vr8EoppVorTfANFB7kz/CkTpTif2QV/U//gk9meS0upZRSypMm+GMwdUAC2SaUvOz0yolr5sCmuWCM9wJTSimlXOpM8CJym4hEt0QwbcUpAzqQY0JJTztoJxTnwOFNUJoPhRneDU4ppZSifiX4DsAyEXlfRKaJiDR3UK1d15gQSvwjKMxxleD3rQBcJffMXV6LSymllHKrM8EbY+4H+gAvAzOBbSLyfyLSq7b1ROQVETksIutrmH+FiKwVkXUislhEhnnMS3FNXy0iyxu0Ry3EEduPHiVbyMnNgb3LKmdkpXgtJqWUUsqtXtfgjTEGOOh6OIBo4EMR+Vstq70GTKtl/i5gkjFmCPAIMLvK/CnGmOHGmOT6xNjSQkZcTKiUsPXHjyF1KcT0tDM0wSullGoF6nMN/jcisgL4G/ATMMQYMwsYBVxY03rGmIVAZi3zFxtj3PeZLQESGxK4t/UaPY10ogjY+DGkLoMeJ0J4J8jSKnqllFLe51ePZWKAC4wxuz0nGmOcInJ2E8VxPfCF5+aBr0XEAC8YY6qW7r3O18+PzdEnMz7rE8BA1zGQvk1L8EoppVqF+lyDfwCIFZHbXS3qR3rM29TYAERkCjbB3+MxeaIxZiRwBnCriJxUy/o3ichyEVmelpbW2HAaxG/ohfi4G9cljoHoHprglVJKtQr1qaL/E/A6EAvEAa+KyP1N8eYiMhR4CZhujKm4v8wYs8/19zDwCTCmpm0YY2YbY5KNMcnx8fFNEVa9DR53GgdMDEW+4RDb2yb43P1QVtyicSillFJV1aeR3ZXAaGPMA67S/AnAVY19YxHpBnwMXGWM2eoxPVREwt3PgdOAalvie1tYUAAfxf2K/8jllCMQkwQYyN7j7dCUUkod5+qT4PcDQR6vA4F9da0kIu8CPwP9RCRVRK4XkVtE5BbXIn/G1go8W+V2uA7AjyKyBlgKfG6M+bKe+9PikiZdyTP5k1i4Nc2W4OHIavq8Q7DzB2+EppRS6jhWn0Z2OcAGEfkG2/jtVGCpiDwNYIy5vbqVjDEzatuoMeYG4IZqpu8Ehh29Rut02qAOxIcH8uaS3Uy5qIed6NmS/qs/wIZP4e6dEBzlhQiVUkodj+qT4D9xPdwWNE8obZO/rw8zRnfl399vZ2/JQLr6h1aW4IuyYNP/wJRDyiIYcI5XY1VKKXX8qDPBG2NeF5EAoK9r0hZjTFnzhtW2zBjbjWcW7OCdZXu5x7Ml/boPobwEfPxgx3ea4JVSSrWY+rSinwxsA54BngW21nbb2vGoU2QwU/sn8N6yvZRHdYdDG6C0EFa/DR0GQ+9TYMf33g5TKaXUcaQ+jez+DpxmjJlkjDkJOB34Z/OG1fZcNa47mQWlrIyYalvRv3AS7F8Fw6+AXifb6/I6EI1SSqkWUp8E72+M2eJ+4bqlzb/5QmqbJvSKIykulL/uHQiXvw95B8HHH4ZeAj2n2IV2aileKaVUy6hPgl8hIi+JyGTX40WgVY7w5k0+PsIVY7uxfHcWG8NOgFsWwjVzITQO4vpARBetpldKKdVi6pPgbwE2Are7HhuBWc0ZVFt10ahEAv18eOuX3XZ0ue7j7QwR6DUFdv0ATqd3g1RKKXVcqDXBi4gvsMYY8w9jzAWuxz+NMSUtFF+bEhUSwPThnfl4ZSrp+VUOUeeRUJwDeQe8E5xSSqnjSq0J3hhTDmxxdSur6uHmSb0odTh5ceHOI2e4x4vP3NHyQSmllDru1KeKPhrbk918EZnrfjR3YG1Vr/gwzhnWmTd+3k2GZyk+tpf9m6EJXimlVPOrT092f2r2KNqZ207uzdw1+3npx13cM62/nRiRCL6BWoJXSinVIupTgj/TGPOD5wM4s7kDa8t6J4Rz9tDOvLE4hZxCV6d/Pj52tDm9F14ppVQLqE+CP7WaaWc0dSDtzaxJvSgoLbct6t1iemoVvVJKqRZRY4IXkVkisg473Otaj8cuYF3Lhdg2DewcwUl943n1pxSKy8rtxJietkc7z1vlSgtg8+dgjHcCVUop1S7VVoJ/BzgHmOv6636MMsZc0QKxtXm3nNST9PwSPlm1z06I7QWOYsjdV7nQgsdgzuWw6TPvBKmUUqpdqjHBG2NyjDEprnHdU4Ey7HjwYXrbXP2M6xXLkC6RzF64E0e5E2JcLendDe0KM2HZK/b5/IegXAfpU0op1TTqM5rcr4FDwDfA567H/+qzcRF5RUQOi8j6GuaLiDwtIttd1f8jPeZdIyLbXI9r6rU3rYyIcOuU3uxKL+CjlalH3yr3y/NQVgBTH4CM7bDyDe8Fq5RSql2pTyO7O4B+xphBxpghrsfQem7/NWBaLfPPAPq4HjcBzwGISAzwADAWGAM8ICLR9XzPVuX0QR0Y3jWKf36zjeLgDuAXBJk7oTjXJvj+Z8PEO6HbeFjwuB1mVimllGqk+iT4vUDOsWzcGLMQyKxlkenAG8ZaAkSJSCfskLTfGGMyjTFZ2NqD2k4UWi0R4Z5p/TmYW8zrP++B6CRbgv/2Adt17Ul32b7qT/odFByG3T95O2SllFLtQH06utkJLBCRz4GKrtmMMf9ogvfvgj2BcEt1Tatpeps0rlcsk/rG8+yCHVzXOwn/Hd9CeSlMuAM6j7ALdRsPPn42wfep7s5EpZRSqv7qU4Lfgy1BBwDhHo9WQURuEpHlIrI8LS3N2+HU6O5p/cgpKmNlfoxN7n3PsNfe3QJC7IA0uxd7L0illFLtRp0leGPMQ1WniUh9Sv71sQ/o6vE60TVtHzC5yvQFNcQ3G5gNkJyc3GpvJh/UOZLpwzvz5Ib+vDHoQoLPe8r2buep+3j4+RkoKwL/YK/EqZRSqn2oraObHz2ev1ll9tImev+5wNWu1vQnADnGmAPAV8BpIhLtalx3mmtam/a7U/ux2tmLhwPuhKCIoxfoPh6cZZC6vOWDU0op1a7UVkUf6vF8cJV5Up+Ni8i7wM/Y3vBSReR6EblFRG5xLTIPe41/O/Ai8CsAY0wm8AiwzPV42DWtTesWG8IVY7vz3rI9LN6RfvQCXccCotX0SimlGq22qnZTw/PqXle/AdtJTm3zDXBrDfNeAV6pz/u0Jb87rS+LtqVx2zur+Oy2iXSO8qiKD46CjoO1Jb1SSqlGq60EHyUi54vIha7nF7geFwKRLRRfuxMe5M8LVyVT4nByy1srKHU4j1yg+wTYuxQcpd4JUCmlVLtQW4L/ATgXONv13N0X/dnAwuYPrf3qnRDGExcNZW1qDi/9uPPImT1OBEcR/Pwf7wSnlFKqXaixit4Yc21LBnK8OWNIJ6YN6si/vt3G2UM60y02xM7odwYMvtD2TR8YDmNurHtjxTkQEG5b5RsDr58Do2bCkIuadR+UUkq1XvW5D141kwfPHYS/rw/3/3c9xj1crI8vnP8C9DsT5t0F+1fVvpHcA/D3AbD6bdfrfZCyCDbXa7gApZRS7ZQmeC/qGBnEXaf1ZeHWND5a6TGErK8/nPec7dlu439r38jqt+yANXt+tq8Pb7J/D1Y7vo9SSqnjhCZ4L7t6XA/G9Ijhoc82sD+7qHJGcJRtcLfli5pXdjorR6A75Ero7gSfuUMHrlFKqeNYfYaLvVhEwl3P7xeRjz2HdVWN4+MjPHHxUBzlhns+WovT6XEHYr8zIW1z5fCyVe38HrJdA9gc3gzljsoEb5yVz5VSSh136lOC/5MxJk9EJgKnAC/jGtZVNY3usaHcd9YAFm1L5/EvN1fO6OcaQG/LF5CTCu9ddWQnOCtfh+AYOPG3UF4CGdvg8Eab8AEOrWu5nVBKKdWq1CfBl7v+ngXMNsZ8jh14RjWhK8d24+px3Zm9cCcv/OAqsUf3gIRBsOFjeOdS2DQX3jgP1syB+Y/Apv/B8MvtIDUAB9dB2hboO822qndfh8/YAUVZ3tgtpZRSXlKfQWP2icgLwKnAX0UkEL123+REhAfPGURmQSmPfbGZ3glhTB3Qwd42t+hJEF+48GX45Xn45Ga70qAL4MTfQUAY+PjblvOOIugw0D4Orbe30M2eDD0nw6VVhxRQSinVXtUnUV+CHejldGNMNhAD/L45gzpe+fgIf79kGP07hnPPR2vJyC+BwRfY0vjZ/7D3tV89F055CG5eBBe/CiEx4BcA8f1hy5d2QwkDocNgOLQBlr8KJbmwZR7kH26ZHdm7DP45BAqq6W9fKaVUi6hPgu8EfG6M2SYik4GLabrR5FQVgX6+PHXZcHKLHPzh43WYhIFwzy7bcQ3YceMn3gGdhh65YodB9jo8QHw/26d9SS4s+gfE9QOnA1a/0zI7sftHyNkDe5a0zPsppZQ6Sn0S/EdAuYj0xo673hVooUxxfOrfMYLfn96Przce4p/fbrP3xdelo2vAv8hutge8DkPs65IcOP3/oNs4e0udqdc4QY2T6ep+t65OepRSSjWb+iR4pzHGAVwA/NsY83tsqV41o+snJnFJciJPz9/GM99vr3uFDq4EnzDA46/Y6vreU2Hk1fbe+JYYijZzl/2rCV4ppbymPgm+TERmAFcD7v5P61GkVI3h4yM8dsFQzh/RhSe+2sID/11PiaO85hU6ukrs7gQfGAZT/wxnPgkiMPA8CIyAVW81e+xHlOBbosbAmwoz4e2LIWdf3csqpVQLqk+CvxYYBzxqjNklIkmANsduAb4+whMXDeWGiUm8/vNuLn7+Zw7kFFW/cGgcXPIGnDCrctqJv4UeE+zzgBDbcc6WeVBe1nxBlxXZ/vDDO0NRpu2Ipz3buxS2fQ07F3g7EqWUOkKdCd4YsxG4C1gnIoOBVGPMX+uzcRGZJiJbRGS7iNxbzfx/ishq12OriGR7zCv3mDe3/rvUvvj5+nD/2QN54apR7Ewr4KLnfmZHWn71Cw+cDuEda97YgLOhOBt2/1S/Nzem4SXwrN3276Dz7d/2Xk2f7drfrF3ejUMppaqoT1e1k4FtwDPAs8BWETmpHuv5utY5AxgIzBCRgZ7LGGPuNMYMN8YMB/4NfOwxu8g9zxhzbv12p/06fVBH5tx0AiWOci5+/me2HMxr+EZ6TQW/YNtBjidHCWz9Cv73W1j2cuX0bx+Ev/WExf+GsuL6vYe7en7AOfbe/AOrGx5nW5KVYv9maoJXSrUu9ami/ztwmjFmkjHmJOB04J/1WG8MsN0Ys9MYUwrMAabXsvwM4N16bPe4NbhLJB/cMh4/H+G615aRnl/SsA0EhNgGd5s/twPVgC2hv3UhvHMJLH8Zvn+0stS+7WtwFMPX98NrZ9XvPdwJPqG/7WynvZfgs7QEr5RqneqT4P2NMVvcL4wxW6lfI7suwF6P16muaUcRke5AEvCdx+QgEVkuIktE5Lx6vN9xISkulJeuSSY9v4Sb31xRe8O76gw4B/L2w/6V9vWWeXb8+Kl/hjP+BoUZNkmX5NnBaib8BqbcD/uWQ/be2rcNdt2gKAiOhk7D239DO3cVvfvERimlWon6JPgVIvKSiEx2PV4EljdxHJcBHxpjPLNVd2NMMnA58JSI9KpuRRG5yXUisDwtLa2Jw2qdhiZG8fdLhrFidxY3v7mC4rIGJPm+p9tx5pe/Co5S+PYhiO0D438DPSbaZfYudZW8DXRJrhz0pj632GXuhJie9nnnEbar3LqSnzH20kBhZv33ozUwxpbgffxsX/9F2fVbb+WbkL6tWUNTSqn6JPhbgI3A7a7HRmBWrWtY+7Cd4rgluqZV5zKqVM8bY/a5/u4EFgAjqlvRGDPbGJNsjEmOj4+vR1jtw9lDO/P4BUP4YWsaM19dSn6Jo34rBkfbe+JXvwX/HgXpW+CUB8DXz3Z3GxAOqUshdZldvstIey99UKTtoa4uWbsqE3x3Vwv+ulqY71sJn/8Wfn6mfvtQnf2rWz5pFmVBaR4kjrGv61NNX1oIc38NS2c3b2xKqeNerQne1VBujTHmH8aYC1yPfxpj6nPxdxnQR0SSRCQAm8SPag0vIv2BaOBnj2nRrkFtEJE4YAL2xEJ5uGxMN566dDjLUrK44qVfyC4srd+KZ/0Dzp9tu7LtNg76n22n+/hCYrLtSz51BcT0sn3d+/hCt/F1l+Adpfa2OHeCj+sDUd1g+/za19vj+ug3fHJ0dX59qvcdJfDWBTDvrrqXbUruhN5zsv1bn4Z27kZ57r9KKdVMak3wrirzLSLSraEbdvV+92vsQDWbgPeNMRtE5GER8WwVfxkwx5gjfskHAMtFZA3wPfC463Y9VcX04V147oqRbNqfy2Wzl3Aotx6t3UVg2KVw5wa48mP72q3rGDi8wSbdxOTK6d3HQ8Z2yDtY83Zz9oJxQkxS5fv0PgV2/WCTf03cCT5zhx0Bzxhbjf3GefCXDvDjU7Xvz4ZPbduBQxtqX66puRvYVST4elyHdy+jre6VUs2sPlX00cAGEZkvInPdj/ps3BgzzxjT1xjTyxjzqGvan40xcz2WedAYc2+V9RYbY4YYY4a5/r5cdduq0mmDOvLKzNHszijklH/8wLtL9+B01qPkGxhmW9Z7Shxjk3RRpr3+7ubuMKe6e+h3/gDvXg5f/dG+dpfgwSb40nzYW8PAM8bYBN/ndDsk7oZPYP1Htho7dx/E9oKFT0JBRs37sewl+7cgrflHsHOW2/01prKBXYeBEJpQvyp69zLZuyvvZFBKqWZQnwT/J+Bs4GHsLXPuh2pFJvaJY95vTmRQ5wj+8PE6rn99GTmFx9BjXeIoj+ceCb7jMDvu/O7F9trz4c02Qe1cYG+x2/sLpPxor+HH96tcL+kkez/89m/h4HqYc8WRvdulb7Wl7/5n2WXXvm+r2rskw6+WwMWvQVkB/PgPm1RTlx+Z7A+ssW0Gep9qXx/e1PB9boitX8Ib58KWL2wJPjjGDu4TkwSZKXWv7y7Bl5fauxmUUqqZ+NU0wzV6XAdjzA9Vpk8EDjR3YKrhkuJCeffGE3hzyW4e+d9GzvnPjzxz+UiGJEbWfyPB0baxXeauygFswDbC6zrW9mW//BVbyg+Nh5J8W2K/5n/2en15mR2f3i0wHLqdAOs/gVVvQ2E6hHWw49tDZfV89/GAgc9+A76BcN5z9tp/fD8YfrltlHZwna3uH3k1nPtvu96yl23nPac9Atu/sQk+6URY/S5s/NS2cO89FZKva8yhrXRwnf278g07PG90d/s6OsnebliXzF0gPvb4ZaVAZGLTxKWUUlXUVoJ/CsitZnqOa55qhUSEq8f1YM5N4yh1ODnv2Z947ItNFJU24Fa6kVfbh2eiBhh1DXQeCSf93ibYpEk2eV49F0Jj7TX3quuArabP2WMTdu9TYM27lbfE7f7ZnijE9ob+59jW+qc+DPF9K9efdK9NigdWQ3QP2POLne50wqbPYOC59qQkKArSNtmS/nd/sXcCpC6Dr+63feQfq9KCyueHXU1Btn0NB9ZClCvBxyTZSwp1vU/mTnsMQRvaKaWaVY0leGzpfV3VicaYdSLSo/lCUk1hVPdovrrjJP5v3iZe+GEn8zcd5unLRjCwc0TdK4+7tfrpA6fbh9vIq+sXzNBLbXKedC+YcnhuPKx4zQ6Gs2exLeGL2JOEu3fZEwFPUV1h1mJbQ7D0JdvbXnEO5B6wbQWSTrLrJwywJfi0LZCbCuc8DZFdbE99OxdAvzNsg72dC2zjQp96XKFa/Q787064fRVEdLbbTxhkGyIWpleW4N3tDrJ22178quMotQ0RB19g+xnQhnZKqWZU2y9cVC3zgps4DtUMIkP8+etFQ3nz+jHkFJVx3jM/8dyCHZQ6WrhxV0Qney09oT90GAQ9p8AvL8Dc2+31+G7jK5etmtzdYnvZyweJowBj7513V+93G2f/JgywJezt39jXvadCj5MgMNL2v1/qupa/83tbfV+X8jL4/jHbXW/Kj/Z2vIwd0P/Mypije9i/7gR/uJaW/O67DOL62pMWdwl+9buwp4ZGiEopdYxqS/DLReTGqhNF5AZgRfOFpJraiX3i+fI3JzK5Xzx//XIzpz+1kC/XH6xfS/vmMP7XkH8Q1n0AQy+DEVfWf1139fa+5TbBhyZUJteEgbZkv+otiB9gr2/7BUDf02yXvKvfsfND4mDB47ZFfG3WzLGXFhD7XunbbA1EfP/K2osYVweLnYZBZDdY8lzN9+67G9jF9LQnBlm7bIPB/95qaxkOb67/cVBKqTrUluDvAK4VkQUi8nfX4wfgeuA3LRKdajKxYYHMvjqZ164djQjc8tYKzvjXIr7bfKjlg+l9Cty0AO7aBhe8AEH1uGzgFhxlS8CpK+z1e3f1PtgSPEDaZlt6d+t/lq3K//Yh2z/+mU/YHvw2fHL09g+ssTULmz6DRU/a5XudbEvY7hb6CQPtZYcZ70GPE+00X3+YeIe95r/rh6O3C5VV8tFJrgSfApv/Z08aEJhzef27u1VKqTrUmOCNMYeMMeOBh4AU1+MhY8w4Y0wtvZ2o1mxyvwS+vuMknrp0OA6nk+teW85jX2zCUd7C1fadR9j78I9Fl2TYtdCWrrt7VO/HD6h83vsUj+en2pb5pXkw9hYYeJ69jj7/ocrOasAOifvh9bDydXjvSpuAJ90D3cfZqv89P9tW+bG97fX7ftOOvI4//AoI7wQ/PFF93Jk7wT8UwhJski/MsLUN0T3givftvfHzHzq2Y6KUUlXU2crIGPO9Mebfrsd3dS2vWj8/Xx/OG9GFz28/kcvHduOFH3Zy8Qs/s3F/dTdNtEKJo+y98WBL8G6hsbbK3j+k8ro82BOJPqfaeYMvsEn5nKegKAdemmq75gX44a+QsQ0u/wCu+gTOfso2zHNva+37NrlXd6cAgH+QHX1v94/2BOHHp+xthG5Zu2xre5HKa/epS+0JR/fxdqS/LV9UVvFn7YacmoZvUEqp2tXWil61c0H+vvzf+UMYmxTDQ5/Z++YvG92Vm07qSffYUG+HVzN3D3sBYdBhyJHz+pwGgk22ns79t+1Rzy/Qvu46Bm74Bt6+GF4+xd7zf3gTDL/SXrP31Hmk7aynNK/yMkBNRs20HfqkLLLV/Nl7Ku/5z9xZ2QmQuztfqLwzoddUe9ng8EZ7GeDN821jvKv/W5+jopRSR9AEr5g+vAuT+sbz96+3MmfZHt5Zuofzh3fhgXMHERns7+3wjtZhEPgFQeJo2wGPp/NqGJEuJMY+PMX3s20BVr1lG+HF94PT/3L0ugEh0Hm4vb6eMLD22PyDK2P47A7bIc7EO+30rBTo6xp6112Cj+xmL1dAZbuB7d9CSZ7tm78w3ZboPccLUEqpetAErwCICgngkfMG8+uTe/PKT7t4adEulqZk8tSlw0nuEVP3BlqSr7+tPvfs8/5YhcTAhNvtozbdTrAJPr6Ge9yrc+Lv7MnDD3+1yV18YOgldl5QpG0sOPiiyuQd0dmeQGyfX9kgrzjH3l4X1eDxnpRSx7n69EWvjiMdIoL4wxkDeP/mcRgDFz3/M5c8/zOfrz1AiaMBveE1t+EzoNvYlnu/fmdCYMSR/fPXJaorjLwKVr1pq+zPeRo6elxS+NUvMOnuI9fpPdU25lv/sT0BgMrucZVSqgE0watqjeoezZd3nMj9Zw1gX3YRt76zkjGPzufBuRtIzSr0dngtr/t4+MNeW8puiBN/Z7vQnfAbO0SvJx+fo6vee021A9GU5MDUBwDRBK+UOiZaRa9qFB7kzw0n9uTaCUn8uD2dj1ak8vYvu3lryW4uGNmFX03uTY+4VtwYrzWITIS7tlY27qtLt3F28JzgKNuCP7a3Jnil1DHRBK/q5OsjTOobz6S+8ezP7s/shTt5d+kePlyRyrnDOvPrk3vTOyHc22G2XvVN7mBb/5/ygB2Ax8fXVunvW958sSml2i0xNXWr2QYlJyeb5cv1x7AlHM4r5qVFu3hryW6Kyso5c3AnfndaX3rGH2PnNap6i/5hO7+5Z7ct1SullAcRWWGMqbZxULNegxeRaSKyRUS2i8i91cyfKSJpIrLa9bjBY941IrLN9bimOeNUDZcQHsR9Zw7gx3tO5tbJvVmw5TCn/XMhf/xkHWv2ZtOeThy9qtNQ+/fQeu/GoZRqc5qtil5EfIFngFOBVGCZiMw1xmyssuh7xphfV1k3BngASAYMsMK1blZzxauOTUxoAHed3o9rxvfgX/O38t6yvbz9yx66xgRz1pDOnD20E4M6RyB6H/ex6ehK8AfXQY+J3o2lJRhjR/GrqbdAgLIi2Py57fPfWW67D47ubm+bdD8CW+CSkaPEjg7or4NrNjtHie3ZMabn0X1f5B6w41kEaHugqprzGvwYYLsxZieAiMwBpgNVE3x1Tge+McZkutb9BpgGvNtMsapGig8P5C/nDeH3p/Xnq40H+d/aA7y4aCfP/7CDAZ0imDGmK9OHd2mdHee0ZmEJENYBdi+GMTfXbwz7qrJS7HC5icn2LoBfXrC37U1/5sjb9qraucAuGxJjTzT6n2UbDZY7YP9K2zFQUOSx7plVVgzlJXY76dvgk5tt97wz3oEuoyqXK3fAwTWw6m1Y96G9yyA4xv6olxXZDoHcfPxh8r22g6Gahh/OOwgr34TsFDvAT6dhtqvg+P6VdzYYU9nJkOcJqjG22+Iv7wWnw/ZeOOBcG4t/kG0kGRJTe9uLtC12dMPdP0Fpoe1m+YKXILxD9cdo3wrbIVJASO3H0+m03S3vX2U/6y6jbDylefY2T8/9KHfYPhZC42o+IcpKsbGC/bzdHTRl77Xfobh+0GFg5UnOtm9g+SsQ1d3GO+AcG7OjFDK2u8Zx8IP1H8LG/8LgC2HQ+Tau3P2w+N+w+m3bQ+Wg82x8OxfAoQ32WPc4ES5/zx5rY2DFq/DFvXZfL3vbdoIFkHfIfpd8fOGcf9nv18In7fb6nAZJJ0FYR/u+eQdg/2r7WWTvgZBYu53k6+z6znLIP1R5B822b+Cnf9neLzsOsd1NH1xnO97qOtYOLZ3yI3QcbN8rorPtmKsww+5j17F2XgtotmvwInIRMM0Yc4Pr9VXAWM/SuojMBB4D0oCtwJ3GmL0ichcQZIz5i2u5PwFFxpgnq3mfm4CbALp16zZq9+7dVRdRXpJZUMrna/czZ9leNuzPJcjfhzMHd+LMIZ2Y2CeOIP8afnzVkT79lf3Ri+llk3TaZtvf/rAZto993wD7A+1OKIc22tHy+pxmSz1vnmd/oNzE1y4vAld9aq/tZ+60ySAo0iaTBY/Dtq/tj6DTYROo+NgfxkMboeCw7dv/9Eftj2H6NnsSkrLILheT5BoWN8n+YPr6266Ad35vk1DXMXabGz6Fklx7z3/2HpsoAsKgIB3G3mwT1YE1UJxtY/cLsl37Dr/C/ti7T3hK8m1f/5k7Yf1HNnm4ewhM324TZ2xvm8yc5bZLYEcJhHe075exHTD2ZCpxNBRl2fctdY0lEBIHcX1scso7YJdPHA2RXWHjp7Yk78nH315e6TzCvm+HQfYOiaIsmPd7u4742g6UgqNhx3e2G+SZn7tOyD6zsTpKYfHTkLvPfjYDzoHMFDi41vau2HOy/TxSFkFpgf2sHMUen7Xr+Bin7SxpyCV2/s4f7PfIWQYB4TDqGpusMnfZXhT9AiB1ud2um1+wHRQpqju8cro9DgCBkXDyH+3toJ/Osp93aT6UFdqTsF4n2/0ryrTf29B4O7BSYIT97DsNs/uZvgUQ6H+m3afMHfY4dh1jH/4hsOAx6DYeBp8Pm+fBjvn2e5C+zW5r1LUQ0QkW/8e+RmyJ3z/UxhsaBwVpNm7fQPu9dH/GvoG2Jqgw0343e02Fk+6Cr++3/xMjrrKf5xd3230oyrLHMiDcfr4HVtvXfsF2gKqD6yrfy9OpD9vbZptIbdfgvZ3gY4F8Y0yJiNwMXGqMObkhCd6TNrJrvdal5jBn2R7mrt5PXomDkABfZo7vwS2TexERpKX6WpU7YNNcWPIs5KTaUmbeAfsD7eYbaO/V9/G1Xd1CZYnNPwQueRNyU20CHHKx/cF/7RzXePfubQRAbB84vMH+WJ/4W1tr4Bdok+eqt2wHPB0G2Vv4lr9if/jc3D9svgH2fbJS7D39njoMsT+qB9famAdOtycCqctsAjvtEZuU3p1h7x5IGGiTYGiCTVADzq671sAYWzpe9HdbeorvD/kHbfIqzLQDFfU/x+5fbC+7Tt5BO9DP7sX2fYNjoMtIm6yM05XUd9jnwTHQ+2SbTHx87YnJ4U22JqGsyCa27N12EKND612JBpvIjbHzJ/7WlhDdJfbNn8OcK+xJRMb2I08YEkdD8vWw/RsbY1xfm4z3LrVJMTQBek2xSUfElqq7jLInBanL7LYCQu0IjDsX2JOUbifYMRZikmxpc/3Hdthi8bHfF0eJra0ZcQUkTbYnDv+7w54whsXbHhYvecOeDCx72Z64AXSfADPm2JOmPYvh52ft9ntPtTEeXAfpW22yHDjdnrgufcl+Tp1H2A6sonvY45S+zSZrz9qFdR/CxzfafQrvbE8Cx99uTzg/nWXfq7zUngxf+pb97n76K5t4z/q73ef9q2wNVPZuezkotrf9nnUZVTmGxYrX4PO77AlQSCz0PQPWzqmsRbjsHfs9zthhazZ8/e0J1sH1tnQeEGpPZA9vrDwRCI6x+xOacPRlhkbwVoIfBzxojDnd9foPAMaYx2pY3hfINMZEisgMYLIx5mbXvBeABcaYWqvoNcG3fqUOJ0t2ZvDhilTmrtlPdIg/Uwd04ISesUwb3JGwQL1zs16MsSWsg2vsD0lWik0Axbkw+npb4ln9jv0BuvClIwe3ccveC8tesokzujvs+N4mhP5nQ/K1dV/Hdpbb8eydDltSTxh45CA/znKbZIpz7A9pRJfKhFZa6Dr5qOH6tdNpS+1Vxw9oa4yxtRF7l8DGuTa5T/1z5aBDnn5+Fr57xCb+CXe4OjzKPfKyQVX5aTYB1ffSTWGmTXpVr1fnHbKfU3T3mi8t5KfB62fbE5qr/2u/Y+593DTXfh8n/6HuywiNlbnT/o1OOvq4OJ022btrjRpj71J7QjXu1/YSyuFN9uR59I1HD2blRd5K8H7YavepwD5gGXC5MWaDxzKdjDEHXM/PB+4xxpzgamS3AhjpWnQlMMp9Tb4mmuDblvX7cnhuwQ4W70gnq7CM6BB/bjypJxeOTKRDROv5B1KqxTidx9bOoqWUFtg2C5FdvB2JcvFKgne98ZnAU4Av8Iox5lEReRhYboyZKyKPAecCDiATmGWM2exa9zrgPtemHjXGvFrX+2mCb5ucTsPKPVn85/vtLNhir1n1TghjQq9YxveO46Q+8QQH6PV6pZSqymsJvqVpgm/7Nh/M5YctaSzekcHSXZkUlZUTFeLP5WO6MXVAAr3iw4gKqeUWKqWUOo5ogldtUqnDybKUTN78eTdfbzyI0/VVHdczlvvOHMCQxEbeoqWUUm2cJnjV5h3MKWbjgRw27s/l1Z9SyCgo5cQ+cZw2qCPDE6OICw8gITwIXx/tUEcpdfzQBK/aldziMl5atIvP1uxnV3pBxfTY0ABOH9yRqf0TGNU9WqvylVLtniZ41S4ZY9iRVsDOtHwO55WwZGcG320+TGFpOQBjesTw+2n9GN2jjd9qpZRSNdAEr44bxWXlrN6bzbJdmbz1y24O5ZbQPTaEcqchITyQc4d15pxhnYkNa8AQrkop1UppglfHpaLSct74OYW1+3II9PVh88E8Nh7Ixc81vv35I7twyoAO2mWuUqrNqi3Ba7dhqt0KDvDl5km9jpi25WAeH69K5b+r9jN/82HCA/0YnRRDUWk5IjCocwSje8QwdUAHbbCnlGrTtASvjkvlTsOSnRl8vHIfG/bnEBboR1m5k00H8igtd5IUF8qNJ/bkhJ4x9IgNxUeTvVKqFdISvFJV+PoIE3rHMaF33BHTSx1O5m86xNPfbee+T9YBEBXiz9lDOzF9eBf6dgjXIW+VUm2CluCVqoYxhk0H8li3L5uftmfw9caDFJfZEb4igvzoFhtC95hQhiRGMrJbNEMTI/VavlKqxWkjO6UaKa+4jMU7MtiTUcieTPvYmZ7P3swiAPx8hAGdIugYGURcWADTBnfipD5xSE2jgCmlVBPQKnqlGik8yJ/TB3U8anp6fgmr9mSzck8W61Jz2JtZyC87M3h36V76dQhnbM8YusWEcPqgjnSNaeZhNJVSyoOW4JVqYiWOcj5bc4B3ftnNtsP55BU78PURzh3Wme6xIeQWORiaGMm0wR21Wl8p1ShaRa+UF+3LLuLVH3fx9i97KCorJ8jf5//bu/sYOerzgOPfZ2bfd+/9zu/vNi8xpMbU0IQmRCpJA6g1tE0i6BttkFClpGqKqooIKUJpkUqqtlGjtAkVKDRKAymF1m2TNg1OG1UJBHCMscH49QCfz/f+tu87O0//mPFlfb6zz4a7fenzkVY7+9vZved3v5l5Zn4z81uKFZ+OZJTr1neyoi1ONOJQ8XyuXt3Ox65fR0fKLuQzxlycJXhjGkDZ83EEHBGePzHG0y+f4thIlqHpIlVfcUQYnimRiDps7E4zXazw0WtW8dDua+odujGmQdk5eGMaQCzizE7ftK2Xm+bcogdw6PQU3/zxW4zMlJjIVfjaD/u5c+darlvfuYyRGmNagXPxWS6fiNwqIm+IyDEReWCe9+8XkddE5ICIPCciG2veq4rI/vCxZynjNKZRXLOmgz+987189bd28fjv3kBvJsbD//4ardTTZoxZHkuW4EXEBb4M3AZsB+4Wke1zZvsJsEtVfwZ4GvhCzXsFVb0ufOxeqjiNaVSZeIT7P3IVL/ZP8B8Hz9Q7HGNMk1nKI/gbgWOqekJVy8CTwB21M6jq91U1H758Hli3hPEY03Q+sWsdV69q4w+/tZ/H/vckVd+O5I0xi7OU5+DXAm/XvD4F/NwF5r8X+E7N64SIvAR4wJ+p6j+/6xEa0+AirsMTn7yRzz7zKn/yb6/xpb1HycQjrOlI8v6tPdywqZsrV2boa4vboDrGmHM0xEV2IvKbwC7gQzXFG1V1QES2AHtF5FVVPT7PZ+8D7gPYsGHDssRrzHJa2Z7gsXt28a8HBvnR8TGKlSonRrJ8ae9Rzh7Q92bi3HxlLz+7sYt4xCXiCBFXSMVcNnSn6UpFOTVRYKpQYeeGTtoSwW14vq9kyx6lik9POmY/qmNMC1nKBD8ArK95vS4sO4eIfBh4EPiQqpbOlqvqQPh8QkT+G9gJnJfgVfVR4FEIbpN7F+M3pmGIBAPl7N6xZrZsKl/h4Okpjg1nefnNCfYeHuaZfeetYueJOMIVK9uYzJcZmi7O7iTEXIdVHQlKXpV8ucq6rhRXrMiwsj1OdzrO1r40V69qZ3imyJGhLNPFChXPpy0Roa8tQV9bnL62OKs7EvMO4FOsVBmZKdGejNoP9hizDJbsPngRiQBHgFsIEvuLwK+r6qGaeXYSXFx3q6oerSnvAvKqWhKRXuBHwB2q+tqF/qbdB2/+P6v6ytB0Ea+qeL6P5yszRY+3xnOM5yqs70qSjLn88PgYh05P05eJs6YzQUcyStR1OD1ZYHCqSDLqkog6vDme59hwlrFsmUKlekmx9GZiiAjThQqVqo+IzF4/4DrCro1dbOhOcWa6yEzRQwS6UzF2buhka18GEWFgssAPjowwNF1k16YudqzrnN1xyJY8SpUqfW0JVrbHWdmeIBOPcHwky8BkgStWtHHlyuB7yp5PMmYjBprWVLeBbkTkduCLgAs8rqoPi8jngZdUdY+IfA94LzAYfuQtVd0tIjcBXwV8ggsBv6iqj13s71mCN2ZpZEseb5yZ4ejQDH1tca5a1UZ3OkbUdZgpeozMlBiZKTE8U2RwqsipieDa2bZElKgrqEI6HqEvE+et8TzPHR5mPFdiVUeS9kTQkTg4VeTYcPacv7ulL83aziT73pwgV760nQzX+elOxRUrMrx/aw8x16FQqTKWLTOeL9PXFmdzTxrPV6YKZQCirkPUdYi4Qjyc7krHWN2RYFVHglXtCfrHcuw9PMx4rkJHMkq+7HF8JBiWOBVz2dKX4e4bNnDt2nZGsiVOjOQ4MZJjZKaEr0rUFTpTMZJRl2zJY7pQYbpYYbrgBT0jVWXHug52rO9EBIoVn5JXpeorG3vSbFuRQYBcyePocJbjI1nWdCS5Zm07riNkix65UpVsyWNle5yNPWmyRY9Dp6eIR1229WUYz5c5cGqSmOuwY30nqZjL6cliuKNXoFxVutNRKp5yYjSHI3DT1l6uXduO4wgx15nd4SqUq4xmS5S8IM6S51P2/NnnStXHV6UjGaUrFaMrHSMVdTkxmqV/NM+K9jibetKs6UziznOaqFipcnwkS65UxVdlTUeSdV1JPF95azyHr9CZjBKPBPGk4i5R16FQrvJi/zj5ssfWvgwbelKz8yzWeK7MaLbEpp707FgWqsqZ6SIDEwWSMZf2RJT2RJR03KWqiu+zbDuVNpKdMaYpTOUrDEwGv9DXmYqypjMJQKXqc3qyQKXqowqZRISo6zCaLTE0XWJoush0ocLm3iBJHBma4cjQDDHXRQRe7B/n5TcnAEhGXbrTMbpSMYZmirw9nsd1hI5kFBGhUvXxqkrZ8ylX/QVjdR2hKxVlqlAhEXHZuiIzm+wPDkxTqFRJRt1F934koy7tyQjtiSi+KsdHcu/wv/lTsYhD2Vu4LhdzdifNm3MXRzrmEo04TOYr7zREIIhzXVcS1WDnxRHBEThTcyrprFTMpeT5895ZIhJclzKVr5zTho7Ahu4UmUSE0Zkynu+zqiNB1HV4ayzPWC7YyXMdoTM8jXS2LBZx2NidolCpMp4rk7/IDmdvJsaWvgyOQKHiUyxXKVSq/P4vbOPju9Zf8LOXwkayM8Y0hY5UdN5x+KOuw8ae9HnlvZk4V5//I3+8Z3X7ov+mV/VxHZn3LgRVpVz1mchVGJwqcGYq6KHoa4tz85V9dCSjs4MQ1X5+qlDh2X2n6B/Ls6knxZa+zOzOhyNQqSqT+SBJtCUitCWi54x0CDCZL/P64AwRV0hEXOLR4P2To0FvgCPBUeKW3gxbV6QZmCjw+uA0iNAWj5CJR0jFXAYmCxwdztKVinHt2nbKns/xkSxtiSg71nVSrvocODVJ2fNZ25lkdWeSNZ0JYq7DeK6M6whrO5OUPJ8XTo5xItzxKHk+Y9ky5WqV1R1J+triJKIu8YhDLOIQDx8x1yUaEQRhqlBhPFdmMl8mW/LY1JNmU2+akZkS/WM5+kdzvD2Rx3Uc0jEXVaj4Puu6Uly1sm322o1TE3kOn5khHXfZ2pchFnGYyAfXhCgwXahwZqpIRyrKz2/rpSsVDXtRshwfyZEre7xnVTsRVzgzVaTk+Xxk+0pWhHejVKo+U4UKVV/ZtiJDTybG4cEZTo7myMQjdKZibO5Ls74rSbHiM1OsMF30yJW82R6I/tEcJ0dzEO4sJNsTJGMuK9oTi1423yk7gjfGGGOa1IWO4Jd0qFpjjDHG1IcleGOMMaYFWYI3xhhjWpAleGOMMaYFWYI3xhhjWpAleGOMMaYFWYI3xhhjWpAleGOMMaYFWYI3xhhjWpAleGOMMaYFWYI3xhhjWpAleGOMMaYFWYI3xhhjWpAleGOMMaYFLWmCF5FbReQNETkmIg/M835cRJ4K339BRDbVvPfZsPwNEfnoUsZpjDHGtJolS/Ai4gJfBm4DtgN3i8j2ObPdC0yo6jbgr4BHws9uB+4CrgFuBf4m/D5jjDHGLMJSHsHfCBxT1ROqWgaeBO6YM88dwBPh9NPALSIiYfmTqlpS1ZPAsfD7jDHGGLMIS5ng1wJv17w+FZbNO4+qesAU0LPIzxpjjDFmAZF6B/BOich9wH3hy6yIvPEufn0vMPoufl89WV0ak9WlMVldGpPV5XwbF3pjKRP8ALC+5vW6sGy+eU6JSAToAMYW+VkAVPVR4NF3KeZziMhLqrprKb57uVldGpPVpTFZXRqT1eXSLGUX/YvAFSKyWURiBBfN7Zkzzx7gnnD6Y8BeVdWw/K7wKvvNwBXAj5cwVmOMMaalLNkRvKp6IvJp4D8BF3hcVQ+JyOeBl1R1D/AY8HUROQaME+wEEM73LeA1wAM+parVpYrVGGOMaTVLeg5eVb8NfHtO2edqpovAxxf47MPAw0sZ3yIsSdd/nVhdGpPVpTFZXRqT1eUSSNAjbowxxphWYkPVGmOMMS3IEvw8LjbEbiMTkfUi8n0ReU1EDonIH4TlD4nIgIjsDx+31zvWxRCRfhF5NYz5pbCsW0T+S0SOhs9d9Y7zYkTkqpr//X4RmRaRzzRLu4jI4yIyLCIHa8rmbQcJ/HW4/hwQkevrF/n5FqjLn4vI4TDeZ0WkMyzfJCKFmvb5St0Cn8cCdVlwmWrkIcAXqMtTNfXoF5H9YXmjt8tC2+HlXWdU1R41D4ILAo8DW4AY8Aqwvd5xXUL8q4Hrw+k24AjBUMEPAX9U7/guoz79QO+csi8AD4TTDwCP1DvOS6yTC5whuH+1KdoFuBm4Hjh4sXYAbge+AwjwPuCFese/iLr8IhAJpx+pqcum2vka7bFAXeZdpsLtwCtAHNgcbufcetfhQnWZ8/5fAJ9rknZZaDu8rOuMHcGfbzFD7DYsVR1U1X3h9AzwOq03CmDtEMdPAHfWL5TLcgtwXFXfrHcgi6WqPyC406XWQu1wB/D3Gnge6BSR1csS6CLMVxdV/a4Go2kCPE8w9kbDW6BdFtLQQ4BfqC4iIsAngG8ua1CX6QLb4WVdZyzBn69lhsmV4Nf5dgIvhEWfDrt/Hm+Gbu2QAt8VkZclGLUQYKWqDobTZ4CV9Qntst3FuRuqZmwXWLgdmn0d+iTB0dRZm0XkJyLyPyLywXoFdYnmW6aauV0+CAyp6tGasqZolznb4WVdZyzBtygRyQD/BHxGVaeBvwW2AtcBgwTdXc3gA6p6PcGvEn5KRG6ufVOD/q2muRVEgkGfdgP/GBY1a7uco9naYSEi8iDB2BvfCIsGgQ2quhO4H/gHEWmvV3yL1BLL1Bx3c+5OcVO0yzzb4VnLsc5Ygj/foofJbVQiEiVYqL6hqs8AqOqQqlZV1Qf+jgbqmrsQVR0In4eBZwniHjrbfRU+D9cvwkt2G7BPVYegedsltFA7NOU6JCK/A/wS8BvhxpewO3ssnH6Z4Lz1lXULchEusEw1a7tEgF8Fnjpb1gztMt92mGVeZyzBn28xQ+w2rPBc1WPA66r6lzXltedzfgU4OPezjUZE0iLSdnaa4EKog5w7xPE9wL/UJ8LLcs6RSDO2S42F2mEP8NvhlcHvA6ZquiUbkojcCvwxsFtV8zXlfSLihtNbCIbNPlGfKBfnAstUsw4B/mHgsKqeOlvQ6O2y0HaY5V5n6n21YSM+CK5oPEKwV/hgveO5xNg/QNDtcwDYHz5uB74OvBqW7wFW1zvWRdRlC8FVv68Ah862BcFPCj8HHAW+B3TXO9ZF1idN8GNKHTVlTdEuBDslg0CF4PzgvQu1A8GVwF8O159XgV31jn8RdTlGcA707DrzlXDeXwuXvf3APuCX6x3/Iuqy4DIFPBi2yxvAbfWO/2J1Ccu/BvzenHkbvV0W2g4v6zpjI9kZY4wxLci66I0xxpgWZAneGGOMaUGW4I0xxpgWZAneGGOMaUGW4I0xxpgWZAneGGOMaUGW4I0xxpgWZAneGGOMaUH/BzTl9RdOmbSxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training accuracy 및 validation accuracy\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "# Training loss 및 validation loss\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# matplotlib 를 이용하여 accuracy 및 loss 출력\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0, max(plt.ylim())])\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f486da19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 50s 5ms/step - loss: 0.5281 - acc: 0.8404: 1s\n",
      "Test Loss : 0.5281, Test Accuracy : 84.04%\n"
     ]
    }
   ],
   "source": [
    "# Test 데이터를 이용한 학습 모델 검증\n",
    "test_loss, test_acc = model.evaluate(\n",
    "                        test_datagen.flow(x_test, y_test, batch_size=1),\n",
    "                        verbose=1)\n",
    "print('Test Loss : {:.4f}, Test Accuracy : {:.2f}%'.format(test_loss, 100.*test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5da81c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
